{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card Fraud Detection\n",
    "\n",
    "In this project we will predict fraudulent credit card transactions with the help of Machine learning models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business Problem : We are living in the era of digitization and usage of internet has increased exponentially which includes all domains of business around the world. \n",
    "One of the domains that has thrived due to this advancement is Banking sector. As per the reports India registered a 51% growth in digital transactions for the year 2018-19, their safety remains a concern.\n",
    "Fraudulent activities have increased several folds, with around 52,304 cases of credit/debit card fraud reported in FY'19 alone. Due to this steep increase in banking frauds, \n",
    "it is the need of the hour to detect these fraudulent transactions in time in order to help consumers as well as banks, who are losing their credit worth each day. \n",
    "Machine learning can play a vital role in detecting fraudulent transactions.\n",
    "\n",
    "The aim of the project is to utilize modernize tools of future like machine learning to build models capable of detecting fraudulent transactions i.e. \n",
    "to predict fraudulent credit card transactions using machine learning models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_val_predict,StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model \n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from statistics import mean\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the csv file\n",
    "df = pd.read_csv('/Users/syedsaifullahtarique/Desktop/Work/UpGrad/Capstone Project/creditcard.csv')\n",
    "# Displaying first few rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Data Checks\n",
    "# observe the different feature type present in the data\n",
    "# info about the data set\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Checks\n",
    "# Describe the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class     0.0\n",
       "V14       0.0\n",
       "V1        0.0\n",
       "V2        0.0\n",
       "V3        0.0\n",
       "V4        0.0\n",
       "V5        0.0\n",
       "V6        0.0\n",
       "V7        0.0\n",
       "V8        0.0\n",
       "V9        0.0\n",
       "V10       0.0\n",
       "V11       0.0\n",
       "V12       0.0\n",
       "V13       0.0\n",
       "V15       0.0\n",
       "Amount    0.0\n",
       "V16       0.0\n",
       "V17       0.0\n",
       "V18       0.0\n",
       "V19       0.0\n",
       "V20       0.0\n",
       "V21       0.0\n",
       "V22       0.0\n",
       "V23       0.0\n",
       "V24       0.0\n",
       "V25       0.0\n",
       "V26       0.0\n",
       "V27       0.0\n",
       "V28       0.0\n",
       "Time      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for the null value\n",
    "round(100*(df.isnull().sum()/len(df.index)), 2).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here you could see that there is no null value in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of classes\n",
    "classes=df['Class'].value_counts()\n",
    "normal_share=classes[0]/df['Class'].count()*100\n",
    "fraud_share=classes[1]/df['Class'].count()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Share:  99.82725143693798\n",
      "Fraud Share  0.1727485630620034\n"
     ]
    }
   ],
   "source": [
    "# Printing the percantage of normal transaction and fraud transaction\n",
    "print(\"Normal Share: \",normal_share)\n",
    "print(\"Fraud Share \",fraud_share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating a bar plot for the number and percentage of fraudulent vs non-fraudulent transcations\n",
    "names = ['normal cases', 'Fraud Cases']\n",
    "values = [normal_share, fraud_share]\n",
    "plt.bar(names,values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see that the number of cases of the Fraud is very low, which makes the data very imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating a scatter plot to observe the distribution of classes with time\n",
    "plt.scatter(df['Class'],df['Time'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we can see that the variable Time does not provide any useful information regarding the fraud detection, since the fraud seems to be independent of the variable Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating a scatter plot to observe the distribution of classes with Amount\n",
    "plt.scatter(df['Class'],df['Amount'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we can see that the fraud is happening for the transaction happening for the samller amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping unnecessary columns\n",
    "# Above we saw that the variable Time does not contribute to the fraud detection, so we will drop that variable.\n",
    "df = df.drop('Time',axis=1)\n",
    "# First few rows of the data set.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into train & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable\n",
    "y = df['Class']\n",
    "X = df.drop('Class',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, train_size=0.7,test_size=0.3,random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preserve X_test & y_test to evaluate on the test data once you build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of fraud:  492\n",
      "Total number of fraud in training data:  344\n",
      "Total number of fraud in test data:  148\n"
     ]
    }
   ],
   "source": [
    "# Printing the number of fraud in train and test data\n",
    "print(\"Total number of fraud: \",np.sum(y))\n",
    "print(\"Total number of fraud in training data: \",np.sum(y_train))\n",
    "print(\"Total number of fraud in test data: \",np.sum(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the distribution of a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlkAAAHgCAYAAACW1XhnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzde3xdZ33n+89v3yTLtzi2ExLbiZ1gSkxDk2JCGab0DJcSSieh84I26bRNZziToYdM28P0lDDwgplweB0azqGdmYaBtGTa0nFDgF5cSJtSCDRAbOwkToKdhMiOY8t2YtmWLctb2rf1O3+stbaW9t6Stuwt7SXp+3699JL2ukiPLOnxb/2e3/M85u6IiIiISGdlut0AERERkYVIQZaIiIjILFCQJSIiIjILFGSJiIiIzAIFWSIiIiKzQEGWiIiIyCzIdbsBjdasWeMbN27sdjNEZA499thjJ9x9bbfb0Qnqw0QWl6n6r9QFWRs3bmT37t3dboaIzCEze7HbbegU9WEii8tU/ZeGC0VERERmgYIsERERkVmgIEtERERkFrQVZJnZjWb2nJn1m9mdU1z3HjNzM9uaOPbh6L7nzOwdnWi0iIiISNpNW/huZlngHuDtwACwy8y2u/u+huuWA78J7Ewc2wLcArwGuBz4RzN7lbvXOvctiIiIiKRPO5msG4B+dz/g7mXgfuDmFtd9ArgbGEscuxm4391L7v4C0B99PhEREZEFrZ0gax1wOPF6IDpWZ2bXAxvc/WszvVdE5r9nXxrm8Klit5shInOkFjgPP3scd+92U1KtnSDLWhyr/6uaWQb4feA/zvTexOe43cx2m9nuwcHBNpokImnyO19+kk8/9Fy3myEic+R7/Sf4N3+yi33HhrvdlFRrJ8gaADYkXq8HjiZeLwd+HPi2mR0EfgrYHhW/T3cvAO5+r7tvdfeta9cuiEWfRRaVYqnGaEWlliKLRbFcBeDMaKXLLUm3doKsXcBmM9tkZgXCQvbt8Ul3P+Pua9x9o7tvBHYAN7n77ui6W8ysx8w2AZuBH3T8uxCRrqoGThCkc9hAs6NFOq9SC//eR8t6uJrKtLML3b1qZncADwFZ4D5332tmdwG73X37FPfuNbMHgH1AFfiAZhaKLDy1wAlSWJuh2dEis6MWPVQVFWRNqa29C939QeDBhmMfm+Ta/63h9SeBT55n+0RkHqgGAbX0xViQmB0NYGbx7Oh9DdfFs6N/J3GsPjsaeMHM4tnRj856q0VSrlILAGWypqMV30XkglVrqR0u1OxokVkQZ7JUizk1BVkicsGqKR0uZA5mR0efRzOkZVGpariwLQqyROSC1QKvP9mmzKzPjgbNkJbFp1ofLqx2uSXppiBLRC5YNQjSmsnS7GiRWaBMVnvaKnwXEZlKOLuw261optnRIrOjHmSpJmtKCrJE5IK4O5VaaocLNTtaZBbUC9+VyZqShgtF5ILEsVVKhwtFZBbESzgUVZM1JQVZInJBqkHY2SrIElk8xpdwCLrcknRTkCUiFyTubGvqa0UWjfFtdZTJmoqCLBG5IHFnm9LFSEVkFtSCeLhQNVlTUZAlIhckzmRpuFBk8dAG0e1RkCUiFySuyaopyBJZNLRBdHsUZInIBalnsjRcKLJoVAPNLmyHgiwRuSDVuCZLMZbIohH/3WuD6KkpyBKRGTsxUuJrT4Xb+FXrswsVZYksFvHffaXm9TWzpFlbQZaZ3Whmz5lZv5nd2eL8+83saTPbY2bfNbMt0fGNZjYaHd9jZp/r9DcgInPvr584wh3bnuBcqVqfZaTCd5HFo5p4qFI2a3LTbqtjZlngHuDthLvS7zKz7e6+L3HZNnf/XHT9TcBngBujc/vd/brONltEuqkcPbmWq4EyWSKLUDWRvRot11jRm+9ia9KrnUzWDUC/ux9w9zJwP3Bz8gJ3H068XAqotxVZwOIi90oQqCZLZBFKZrI0w3By7QRZ64DDidcD0bEJzOwDZrYfuBv4zcSpTWb2hJl9x8x+utUXMLPbzWy3me0eHBycQfNFpBvih9hqzeudrYYLRRaPZCZLMwwn106QZS2ONfWm7n6Pu18NfAj4aHT4GHCFu18PfBDYZmYrWtx7r7tvdfeta9eubb/1ItIV8ZpY1ZrXa7I0XCiyeEyoyVIma1LtBFkDwIbE6/XA0Smuvx94N4C7l9z9ZPTxY8B+4FXn11QRSQv3VsOF6QyyNHFHpPOqNceiFIyGCyfXTpC1C9hsZpvMrADcAmxPXmBmmxMv3wU8Hx1fGxXOY2ZXAZuBA51ouIh0T5y1CjNZ6V2MNDFx553AFuDWOIhK2Obu10YTdO4mnLgT2+/u10Vv75+bVoukXy1wlveEc+c0u3By084udPeqmd0BPARkgfvcfa+Z3QXsdvftwB1m9jagAgwBt0W3vxm4y8yqQA14v7ufmo1vRETmTjxcWKkFVOLZhenMZNUn7gCYWTxxpz47WhN3RGauEgQs780zPFbVcOEUpg2yANz9QeDBhmMfS3z8W5Pc91XgqxfSQBFJn/rswlqQWCermy2aVKuJO29ovMjMPkBYN1oA3pI4tcnMngCGgY+6+yOz2FaReaMWOCuW5DlyelTDhVPQiu8iMmP12YWBj9dkpTPKmvWJO6AZ0rL4VGrO8t4wT6PZhZNTkCUiMxZ4MpOV6uHCOZm4oxnSstjUgoAVUZCl4cLJKcgSkRkLEks4xFO53cdnHaaIJu6IzIJqzenNZ8lnjaIK3yelIEtEZqw+uzAIqAbjixKmbcTQ3atAPHHnGeCBeOJOtAUYhBN39prZHsJhweTEnafM7EngK2jijkjd6dEKA0OjZDPGnkOn2bbzULeblEptFb6LiCSNDxeO12RBGHxlM63KoLpHE3dEOq8WOBkzCtkMlcTq7zKRMlkiMmNBYlud5ErvaV2QVEQ6K3AnY5DPZuobxkszBVkiMmPJdbKqCrJEFp04a13IZShXFWRNRkGWiMxYcp2s5Eax2r9QZHEIM1nhcKEyWZNTkCUiM1bfIDrwhkxWt1okInMpCKhnsirKZE1KQZaIzFgcTFUT62RBahckFZEOU01WexRkiciMjQ8XTsxkpXRBUhHpsFrgZFSTNS0FWSIyY8l1sjS7UGRxCQLHgYxZlMnS3/1kFGSJyIzVJqyTlViMVA+0IgtenL3OZoxC1rRO1hQUZInIjE2YXajhQpFFJc5eZ2y88D2FW2qlQltBlpndaGbPmVm/md3Z4vz7zexpM9tjZt81sy2Jcx+O7nvOzN7RycaLSHck9y5U4bvI4lKJUtbZqPDdYcLDloybNsiKNki9B3gnsAW4NRlERba5+7Xufh1wN/CZ6N4thBuyvga4EfhsvOGqiMxfcQlGJdBipCKLTS3qADKZsCYL0JDhJNrJZN0A9Lv7AXcvA/cDNycvcPfhxMulQNzT3gzc7+4ld38B6I8+n4jMY3HGqtpQk6XFSEUWvjiTFRe+Q1ifKc3a2SB6HXA48XoAeEPjRWb2AcId7AvAWxL37mi4d915tVREUqM+u7BpW51utUhE5kr89581I5cNN4RXJqu1djJZ1uJYU1fq7ve4+9XAh4CPzuReM7vdzHab2e7BwcE2miQi3RQPC1YCbRAtsthUNVzYtnaCrAFgQ+L1euDoFNffD7x7Jve6+73uvtXdt65du7aNJolIN40XvjfMLkxhKksTd0Q6q1qfXYiGC6fRTpC1C9hsZpvMrEBYyL49eYGZbU68fBfwfPTxduAWM+sxs03AZuAHF95sEemmWnLF9+Q6WSnLZGnijkjnxX/z2YyR13DhlKatyXL3qpndATwEZIH73H2vmd0F7Hb37cAdZvY2oAIMAbdF9+41sweAfUAV+IC712bpexGROVKfXdjQsaZwMdL6xB0AM4sn7uyLL2hn4g7wgpnFE3cenYuGi6RVNbFOloYLp9ZO4Tvu/iDwYMOxjyU+/q0p7v0k8MnzbaCIdMcXvvsCw6MV/s+3v6rpnCfWybJE5WUKFyPVxB2RDotrsrIZzS6cjlZ8F5GWvvnMyzyw+3DLc8m9C1NekzXrE3dAk3dkcanWl3CgPlxYVSarJQVZItJSuRpw7MwYI6Vq07lkTVYysErh1hqzPnEHNHlHFpf6cGEik1VWkNWSgiwRaSnuNPcfH2k6V59dGAQTajFSmMnSxB2RDqsv4ZCoyapquLCltmqyRGTxKVejIGtwhJ/YcNGEc0G98N3JJR7V0laTpYk7Ip2XXIxUswunpiBLRFqKM1n9rTJZ9eHCAMiQzRi1wElZjAVo4o5Ip9W31ckY2YxhKMiajIYLRaSlZCarUS0xu7AWeP1pNoXDhSLSYfEG0VkzLBoy1OzC1hRkiUhLlSkyWbVEJqtaCyhEdRlpGy4Ukc6rzy6MIohc1pTJmoSCLBFpKc5kvXiy2GLR0bjw3akGTiEXLoSewtmFItJhycVIgSiTpSCrFQVZItJSuRqwqi9PNXBePFmccC4eFazWAmqB0xNVv6ufFVn4qonhQkDDhVNQkCUiLVVqzjWXrQCa67LiYcFKLc5kxUGWOlqRhS65ThaEC5Iqk9WagiwRaeLulGsBr35FGGQ11mUFk9RkabhQZOGLV3ePYiwNF05BQZaINImXb7h4aZ41ywoMDE0cLqzPLgwaMlkKskQWvDiTlZ2QydLffisKskSkSVz0XshlWN6b51xp4hqcyUxWTcOFIovKeCZLhe/TUZAlIk3ip9JCNkNfIUuxPHH/wvHC9yiTVR8unNNmikgXNGeyVPg+GQVZItIkzmTlc2GQ1ZjJqtWXcAgzWXllskQWDS3h0L62giwzu9HMnjOzfjO7s8X5D5rZPjN7ysy+aWZXJs7VzGxP9La98V4RSZ84yHr8xdOcGa1weKjItp2H6ueTswsrWoxUZFGp1WcXhq81u3By0+5daGZZ4B7g7cAAsMvMtrv7vsRlTwBb3b1oZr8B3A38UnRu1N2v63C7RWQWxYXvuYxRyGY4Xa1MOJ+cRViqBvV1sjS7UGThq6gmq23tZLJuAPrd/YC7l4H7gZuTF7j7w+4eTz/aAazvbDNFZC7FmaxsxijksvXXseR+heVqkCh8n9t2isjcqwWOkQyyjGrN9ZDVQjtB1jrgcOL1QHRsMu8D/i7xutfMdpvZDjN793m0UUTm2IRMVs4oJYIsdydw6Im20gE0XCiyiFRqXl+IFMJMljPeb8i4doIsa3GsZU9qZr8CbAU+nTh8hbtvBX4Z+AMzu7rFfbdHgdjuwcHBNpokIrMpTv1ns0Yhm53Qeca17fEQIVDPZKXxSVY1pSKdVQuC+pY6EAZZAGNlBVmN2gmyBoANidfrgaONF5nZ24CPADe5eyk+7u5Ho/cHgG8D1zfe6+73uvtWd9+6du3aGX0DItJ58fBgLpOhkMtQC7xe7Bq/bxVkpW12YaKm9J3AFuBWM9vScFlcU/pa4CuENaWxUXe/Lnq7aU4aLZJyYSZr/HUuKh0Yq9YmuWPxaifI2gVsNrNNZlYAbgEmPNGZ2fXA5wkDrOOJ46vMrCf6eA3wJiBZMC8iKZSsyYqDqfhYEGWrevKJ4cKUBlmoplSk42qB1+uxYLxcYLSsIKvRtEGWu1eBO4CHgGeAB9x9r5ndZWbxk92ngWXAlxvS6tcAu83sSeBh4FMNsxJFJIVK1YmzC2G83qIeZCUzWeldjHROakpV8iCLSbVhuDAXDxcqk9Vk2iUcANz9QeDBhmMfS3z8tknu+z5w7YU0UETmXr0mK2P1LFUp6kCnHC5MX5R1PjWlP5M4fIW7HzWzq4BvmdnT7r6/6RO63wvcC7B169bU/SOIdFK1ofC9EA0XKpPVTCu+i0iTcjKT1ThcGNW2FhJBVk96hwtnvaZUZLGpBk4ixhrPZFVU+N5IQZaINCm3yGQ1Dxc212SlcHahakpFOqw6SU3WWEWZrEZtDReKyOISDxfmspnxmqwok1WboiYrbcvkuHvVzOKa0ixwX1xTCux29+1MrCkFOBTNJLwG+LyZBYQPpKopFQGqtaC+OTQkZhcqyGqiIEtEmkw9XBjPLhwPsnIpXoxUNaUindWYycqr8H1SGi4UkSalKZZwqLUYLsxnjYylcrhQRDqsMZOVry/hkLJUdgooyBKRJq1mF47XZIXXJIcLsxkjm7E0Fr6LSIc1Fr7nNVw4KQVZItKkXA3IWLgBbGNNVtBiCYdH95/EHX545MzcN1ZE5lTjEg71TJaCrCYKskSkSbkakIv2zchmwqHAeAixvk5WYsX3jBlmqVyMVEQ6rHHF91zGMKCkIKuJgiwRaVJO1FyYhUOGjTVZcYYLwiArY1Zf3kFEFq5KMLEmy8zIZU2ZrBYUZIlIk0otIJfoRHty2XpNlrdYwiGTATNQ2avIwldrqMmCcMhQi5E2U5AlIk1K1YBsdmLNRT2TFfWjySUcsmYYptmFIotApeYT9i6EsI9QJquZgiwRaRLWZCUzWckgKwykehtqsjKqyRJZFGpBMKHwHcIZhppd2ExBlog0qTSsg1PIZeqF70HL4ULDzNAKDiILX7U2sfAdNFw4GQVZItIkObsQwiL3eO2sOJOV3CA6XO5Bi5GKLAbVwCc8hEEcZCmT1aitIMvMbjSz58ys38zubHH+g2a2z8yeMrNvmtmViXO3mdnz0dttnWy8iMyOcluZrPHhwmyUyVKMJbLwVWtBUyYrp+HClqYNsswsC9wDvBPYAtxqZlsaLnsC2OrurwW+Atwd3Xsx8HHgDcANwMfNbFXnmi8is6FS9aYgqxztS9ZyuDBaJ0tLOIgsfI0rvkOY7Vbhe7N2Mlk3AP3ufsDdy8D9wM3JC9z9YXcvRi93AOujj98BfMPdT7n7EPAN4MbONF1EZkupYQmHQi5TX8Ihnl1YyDWvk6UQS2ThazVcmNNwYUvtBFnrgMOJ1wPRscm8D/i787xXRFKgaXZhtISDu9drsuKV4CGsxzKUyRJZDFoNF2YtDL5konaCLGtxrOW/pJn9CrAV+PRM7jWz281st5ntHhwcbKNJIjKbytUa2cSK7oVchsDDWq24uD1jVn+azaS4Jks1pSKd1SqTlc1kqNZS2AF0WTtB1gCwIfF6PXC08SIzexvwEeAmdy/N5F53v9fdt7r71rVr17bbdhGZJZWaNw0XAhRLtfq2OmEmK7wmG62TlbZMlmpKRTqvVU1WNkO9pEDGtRNk7QI2m9kmMysAtwDbkxeY2fXA5wkDrOOJUw8BP2tmq6LO6WejYyKSYuVqw+zCKKt1rlytDxc2ZrIy6cxkqaZUpMOqtebFSDNmVBVkNZk2yHL3KnAHYXD0DPCAu+81s7vM7Kbosk8Dy4Avm9keM9se3XsK+ARhoLYLuCs6JiIpVm5R+A4wWq7Vs1XZjNW31shYuHdhCtfJmpOaUpU8yGIRBE7gNC/hkDENF7aQa+cid38QeLDh2McSH79tinvvA+473waKyNyrVFsHWefKNYLoYTVj1J9mx5dwmPOmTud8akp/Zqb3uvu9wL0AW7duTd+/gkiHVBMTX5IyGdNwYQta8V1EmpRaLEYKUCxV6zVZyeHCuD7L07eIw6zXlIosJslygaSsmWYXtqAgS0QmcPeoJmu8e+jJhqu7h5msVsOFhpHKDaJVUyrSQZUolZ1tKnw3aoHX+wcJtTVcKCKLR/w0mss2Z7K+se/l+qyiv//hS/VMlhnRBtHp6mDdvWpmcU1pFrgvrikFdrv7dibWlAIccveb3P2UmcU1paCaUhFqUd1VY+F73BdUgoCeTLbpvsVKQZaITFCuxk+qzUFWuRrUt9MxIJOJ3kdLOKQsxgJUUyrSSXEmq3G4MH5drTk9iizqNFwoIhPEQVYykxUXwVeDoF53lbFwuHA8m2VpLHwXkQ6q7/jQWJMVZ7JU/D6BgiwRmSCeIZQsfI8/rkXTtyEcIswkFiRN6RIOItJBpUrzQxgkgyz1AUkKskRkgnomK1H4HnegQeATt9UxI75MG0SLLHzFcrgJdD47MXzIJrLdMk5BlohMMGUmyydmspJb66RxWx0R6azRShhkxXWasXj4sFJVH5CkIEtEJhjPZI0HWfESDbXA68XtFtVj1YcLSeW2OiLSQaOTZLIyidmFMk5BlohMEBeu5lpM0a4F49mqjE1ckFQ1WSILXz2TNdlwoWqyJlCQJSIT1JdwaChszWSMWhDUA6nxTFZ0XrMLRRa8YrkKQD7XvOI7aHZhI61mISIT1IOsxkyWGTUf358wA1y6oqfeqZpqskQWvHi4sDmTFb5XkDWRgiwRmaBUa55dCOPbZsRhlJnxlldfWj9vml0osuBNPlwYvtYSDhNpuFBEJqi0KHyHMMiauITDxPsyqskSWfDqSzjkGgvfw/dVZbImUJAlIhO0WsIhfj1xCYeJ5w1UkyWywI1Vapg1P4Tl4posdQITtBVkmdmNZvacmfWb2Z0tzr/ZzB43s6qZvafhXM3M9kRv2zvVcBGZHa2WcICwsL02ZSbLlMkSWeCK5Rp9+WzTQ1Z9CYeqMllJ09ZkmVkWuAd4OzAA7DKz7e6+L3HZIeDXgd9p8SlG3f26DrRVROZAZZJMVi6qyZo0k2VaJ0tkoRut1FhSaA4dtOJ7a+1ksm4A+t39gLuXgfuBm5MXuPtBd38K0L+uyDw3vkF0c81FMpPVEGOldnahMvEinTNarrGk0Bw6jC/hkL4+oJvaCbLWAYcTrweiY+3qNbPdZrbDzN49o9aJyJwrxUs4WPMSDkGiJivTOFxgpC6TlcjEvxPYAtxqZlsaLosz8dtafIpRd78uertpVhsrMg+Mlmv05SfPZGkJh4naWcLBWhybSVd6hbsfNbOrgG+Z2dPuvn/CFzC7Hbgd4IorrpjBpxaRToufRHPZFoXvUSarsR4LwuHCFHav9Uw8gJnFmfh6uYO7H4zOpbD5IulSrNToLWSbjme04ntL7WSyBoANidfrgaPtfgF3Pxq9PwB8G7i+xTX3uvtWd9+6du3adj+1iMyCyRYjzSRqsqzFs5eRyiUclIkX6aDRcpW+fHOQFfcXZWWyJmgnyNoFbDazTWZWAG4B2qpNMLNVZtYTfbwGeBOJJ0gRSZ9yrUYusfFzLBct4eB4Uz0WxNvqpC7I6kQmfivwy8AfmNnVLb+I2e1RMLZ7cHDwfNopMi+Ehe8tgiyLM1kKspKmDbLcvQrcATwEPAM84O57zewuM7sJwMxeb2YDwHuBz5vZ3uj2a4DdZvYk8DDwqYZZiSKSMudKrTvR8SUcmuuxwvPpq8liDjLx0Xll42VRKJYnCbLqswvT1wl0U1vb6rj7g8CDDcc+lvh4F2Hn1Xjf94FrL7CNIjKHBkdKrF3e03Q8Wx8ubJ3JSukSDvVMPHCEMBP/y+3caGargKK7lxKZ+LtnraUi88BYtE5WIw0XtqYV30VkgsGzJdYsax1kxbMLWwdZ6VvCQZl4kc4qTjJcmDEVvreiDaJFZIITIyWuecWKpuNZS84ubDVcmM4NopWJF+mc0UmGCzMWPmipJmsiZbJEZIITZ0usWVZoOj6+hEPzau+Q2tmFItIhtcApVQOWtBguNDPymQxlZbImUJAlInWlao3hsWrL4cJMoiZr0nWy1L+KLFhjlRoAfS0yWRCuradM1kQKskSk7sRIGWDywnePMlkt7o0DL2WzRBamYjkMslplsgDy2YxmFzZQkCUidSfOlgBaF77HNVm0rsmKD9XUyYosSKNxkNVig2iAfNY0u7CBgiwRqTsxEgVZk2SygoBJZxfGgVdNmSyRBWl0muHCfDaj4cIGCrJEpK4eZE1W+O5xTVarTFZ4TDGWyMJULFeByYcLc1mr730qIQVZIlI3OMVwYT1TFUy2rQ718yKy8MSZrFZLOADkMxkqymRNoCBLROpOjJRZ3pujt8WTai6Koiq1YNIlHEDDhSIL1Wg7he/KZE2gIEtE6gZHSqxtkcWCcAkHCFd0nmwJBwDXg6zIgjRdTVY4XKgOIEkrvosIANt2HmLf0WHcnW07DzWdT24AO9kG0aBMlshCFS/h0CrTDZDLZqioXGACZbJEpO7sWJVlPa2fvbL1vcmCSTeIBtVkiSxU8XDhZJmsghYjbaIgS0TqRkoVlvXmW57LRr1FJXCsxXKkpsVIRRa08eHC1g9iORW+N1GQJSJAmKEaqwSTZ7Iy45msVjVZWidLZGGLhwt7cq1DBy3h0KytIMvMbjSz58ys38zubHH+zWb2uJlVzew9DeduM7Pno7fbOtVwEemskVK4Bs7ySYKsOIiqBj717EINF4osSGOVGkvy2fokmEaFbIZqoExW0rRBlpllgXuAdwJbgFvNbEvDZYeAXwe2Ndx7MfBx4A3ADcDHzWzVhTdbRDotDrKW9U42FDD17MJMShcj1UOiSGcUy9VJ18iCKJNVTVkH0GXtZLJuAPrd/YC7l4H7gZuTF7j7QXd/CmgMYd8BfMPdT7n7EPAN4MYOtFtEOmxkLAqyJstkTbdOVgoXI9VDokjnjJaDSdfIgnCdrIoyWRO0E2StAw4nXg9Ex9rR1r1mdruZ7Taz3YODg21+ahHppHPRlhlLp6vJmmTFd0tnTZYeEkU6ZLQydSYrn1Xhe6N2gqxWg6/t9qJt3evu97r7Vnffunbt2jY/tYh00nSrOWcTkdVU62SlbHbhrD8kiiwG23YeYv/xc4yWay3X0YOwpEArvk/UTpA1AGxIvF4PHG3z81/IvSIyh0YrNQzoybfuFrKZZJDVfH58nazZaN15m/WHRFA2XhaHci2gMMnMQoB8LqPZhQ3aCbJ2AZvNbJOZFYBbgO1tfv6HgJ81s1VRLcPPRsdEJGVGKzV689mWWSqYGGS1XCcrep+mmizm6CFR2XhZDMrVgHy2df8AkM9oW51G0wZZ7l4F7iAMjp4BHnD3vWZ2l5ndBGBmrzezAeC9wOfNbG907yngE4SB2i7gruiYiKTMaLk2Zb1FMvhqFYfF54N0DRfqIVGkQyq1gEJ28rAhl81oxfcGbe1d6O4PAg82HPtY4uNdhE95re69D7jvAtooInNgNFoDZzIThwsnr8lKU5Dl7lUzix8Ss8B98UMisNvdt5vZ64G/AlYB/9LM/ou7v8bdT5lZ/JAIekiURa5cC8hPEWTltXdhE9r0HkgAACAASURBVG0QLSJAlMlqM8hqPbswfJ+y4UI9JIp0SKUakJ+qJiur4cJG2lZHRIAokzXFcOHEIKvVOlnxcGHn2yYi3VeqBpNuqQNhJss9fQ9a3aQgS0SANjJZNvXswpTWZIlIB9QCpxo4PbmpV3wHlM1KUJAlIrj7tJmszDQ1WWkdLhSRC1eqTr05NEA+E55TkDVOQZaIUCzXCHzyhUhhfO9CaL2AVBxkBQqyRBacUjUMnHonWUcPqC/voAVJxynIEhHOjFaAqYOsiUs4tJhdiGqyRBaqUiUMsgpTDhcqk9VIQZaI1IOs3jYL31uv+B6+T9nehSLSAfFwYe80swsBLeOQoCBLRNrMZI1/3DKTFRe+q4MVWXDi4cKeKfqIeA0tLUg6TkGWiIwHWVNkssysns2aKpOl2YUiC89YZfrCdw0XNlOQJSJtZbJgfBmH1ouRxhtEK8gSWWjKcSZriiCrUF/CQX1ATEGWiHCm2F6QFc3QnmS4MHyvTJbIwjNWD7KmmoEcDxeqD4gpyBIRzoxWMKBniunZANmoE211lVZ8F1m4SvFw4RR9RLwYaVnDhXUKskSEM6MVevPZlouMJkV9aOsNoqP3Gi4UWXhK1YB81qbsIwoqfG+iIEtEODNambLoPRYXvk+9d6GCLJGFplSt0TvFUCEkC9/VB8TaCrLM7EYze87M+s3szhbne8zsS9H5nWa2MTq+0cxGzWxP9Pa5zjZfRDrhzGhl2nosSAZZzedUkyWycJWqAYUpit4hsXdhoExWbNogy8yywD3AO4EtwK1mtqXhsvcBQ+7+SuD3gd9LnNvv7tdFb+/vULtFpINmmslqvYRDPLuwo027YHpIFLlwpUpA7zQPYt985jgA33rmONt2HpqLZqVeO5msG4B+dz/g7mXgfuDmhmtuBv40+vgrwFut1XiCiKTScLuZLJtquDB8n6bFSPWQKNIZpWpt2kxW3D9UU9QHdFs7QdY64HDi9UB0rOU17l4FzgCro3ObzOwJM/uOmf30BbZXRGZBu8OFmSkyWZl01mTpIVGkA0rVYMotdWA8052mB61uayfIatXZNP4LTnbNMeAKd78e+CCwzcxWNH0Bs9vNbLeZ7R4cHGyjSSLSKe7O6Y4UvofvU7Z3oR4SRTpgrFKbcksdGO8fUtYHdFU7QdYAsCHxej1wdLJrzCwHrAROuXvJ3U8CuPtjwH7gVY1fwN3vdfet7r517dq1M/8uROS8nSvXqAU+o+HClutkRe9T9hQ76w+JoAdFWfhK1WDK1d5hPMOtZVzGtRNk7QI2m9kmMysAtwDbG67ZDtwWffwe4Fvu7ma2NqqJwMyuAjYDBzrTdBG5UPsHR9i+J3xmmtnswik2iE5X/zrrD4nReT0oyoIWBlltZrJS1gl0U266C9y9amZ3AA8BWeA+d99rZncBu919O/AF4Itm1g+cIgzEAN4M3GVmVaAGvN/dT83GNyIiM1OtBfzL//5diuUaZrBmec+090w1uzCTzr0L6w+JwBHCvumXG66JHxIfpeEhkTDYqukhURazUjXMdk+/I0Qq6zK7atogC8DdHwQebDj2scTHY8B7W9z3VeCrF9hGEZkFR06PUizX+N0bf4x/fcOVfP3pY9Pe005NVpo6WD0kily4c6VoS502Zxem7EGrq9oKskRk4Tl4sgjA665Yxcq+fFv3ZOpLODSfS2OQBXpIFLlQI2NVYOrNoUHDha1oWx2RRergiXMAbFqztO17xocLJ6/JSttipCJyYUZKcZA1TeG7gqwmCrJEFqmDJ8/RV8iyto1arNhU2+rUZxemLJMlIhemHmRNU5OVMcPQEg5JGi4UWYS27TzE9/tPsnJJnr/4weHpb4iML+Ew+QbRw2OVzjRSRFLhXBRkTbdBNIQPYilbxqWrlMkSWaROjJRYvbQwo3umymRlM8YrL1nG//zeQZ48fLoTTRSRFDgbBVnTbasDYT+g4cJxCrJEFqFa4AwVy6xe1v5QIUxdkwXwS1s3sHZZD7d/cTfHh8cuuJ0i0n1x4ft0G0RDFGS5MzxaoaICTQVZIovR6WKZwOloJgtgaU+OP/q1rZSrAXuPDl9oM0UkBc61WfgOYUnB4VOjfPqh5/jzHS/OdtNSTzVZIovI9/ef4JljZzl5rgww40zW+BIOk++fvOXyFTzyobewrEfdi8hCMJPhwkzGOHJ6FIB9etBSkCWymPzht/r5/v6T/Pjl4RZ8q5fNNJMVvm+14nuSAiyRheNcqUohl5m0TCApmzGyGWNFb44D0TIxi5l6QpFFolSt8diLQwD88OgwhWyG5TMMhrKZMMqaKpMlIgvDd58/wbeePc6Z0UpbQ4UAb7p6Nct68/QfH6H/+NlZbmH6LYiarMdePMWJkVK3myGSak8ePkOpGvCvrl8HhFmsmQZL2ejy6TJZIjL//cn3X+C+773A3+w5Mu1q77E3Xr2Ga9etZO2yAkPFCkNRacJiNe+DrGK5yq337uT/fei5bjdFJHXGKjX+5HsvUCxX2XHgJGbwsX+5hdeuX8mrX7Fixp9vutmFIrIwBIGz6+AQq/ryVANvO5MVWxPVey72IcN5P1z42ItDlGsBjx442e2miKTOXz9xhP/8t/v41rPHGTg9yitW9PLg0y9xy+uvOK/PF2+boRBLZGF7/vgIZ0Yr3P2e1/LDI2c4MjQ6o/vXRDtJvHDiHK+7ctVsNHFemPeZrB1RcPXiySJHT4/y/Mtn+dUv7OTUIk9RyuJ16GSRM6Phqut/+fgRAL7Xf5JDJ4tcNYN9ClvJtjG7UETmr3h4b9fBUwC8YdPF3HXzj/PWay6d0edZ1VcglzEODI7w3edP8PP//ZF6v7SYLIAg6xSr+vIA7HzhJH/8yAs88vwJvrw73Crk8Kkiz72k4jtZuErVWn2z56FzZd713x7h1nt3cGBwhB8cPMWv/7ON5LJGNXA2rVl2QV9rfLjwgpstIinzxKEhXvd/f4Pf+fKTfHn3YZb35vju8yfYtvPQjD9XNmNcsbqPF06c495HDvDDI8P87ZNHZ6HV6dZWkGVmN5rZc2bWb2Z3tjjfY2Zfis7vNLONiXMfjo4/Z2bv6FzTw3qsJw+f5hdfv4EVvTm++cxxvvZU+EP80u7DjFVq3PpHO3jv577P0LkytcD5s0cPMjBUrH8O10aWMs+4O48fGqJUrQHwwS89yVs/8x1+8MIpPvvtfs6Wquw7Nsx7P/coAGuX9/D2LZfSk8uw6UIzWZn5l8lKa/8lkgZPHBqi//gIAJ/7zn4Ch7/74UscOHGOjauXXtDf+lVrlvLYi0M88vwgAF9+bACAv9lzhL//4bELb/w8MG2QZWZZ4B7gncAW4FYz29Jw2fuAIXd/JfD7wO9F924BbgFeA9wIfDb6fB3x2ItDVAPnTVev4YZNq/naU8c4V65x6w0bODB4jt++fw8DQ6OcLVX5r998nnse7udjf7OX9/3JbkbLNe55uJ9//nsP88MjZ3B3vvjoQf76iXB4pRY4//SjQUbL4X9k1VpAsVztVNNFcPcJQf7x4bF64HR8eIy/emKASi2gUgu462/38f88+Ay1wLnvewf5V5/9Pv/Hnz/OP+x9ia8/fYxsxvjAtsf500df5CevWMW161Zy8lyZTWuWsqqvwD+7eg0fedc1LClc2J/fdCu+p02a+y+RuXJ2rFLftPmFE+f4XztfpFIL2HP4NL/0+R384ucf5Xv9J/iHfS/ztmsupViqcnasypWr+y7o65YqAcfPlnCHn7pqNU8ePs2ffv8gv/2lPdyx7QmeODTE0dOj/McHnuSxF8PhyVrgC+r/2nYK328A+t39AICZ3Q/cDOxLXHMz8J+jj78C/KGF4e/NwP3uXgJeMLP+6PM92onG7zhwklzGeN2Vq3j++Aj/+MzLvPKSZXz0XVv42yeP8fd7X+Jf/NhaXrFyCX++40UCd1535SoePzTEzfd8lx+9PEIhl+Ff//FOtl65im8+exyA7/Wf4PnjI+w5fJorV/dx2xs38mePHuTI6VF+7Y0buWR5D1/c8SKXLO/h1964kaePnOH7+0/y5let4foNq/iHvS9xtlTlXddeRqUW8MjzJ1i/agn/7Oo17Dt2hv3Hz/G6jat4xYre+rj36zdezPBYhb1Hh9mwqo/Nly7jRy+f5cTZMq+5fAV9hSx7jw7TW8hyzSuWc2KkxIsni2y4uI9XrOzlwOA5iuUqr7xkGTjsP3GOFb05rri4j8GzJV4eHmP9xX2sXJLn4Ilz1ALnqrVLGS0HHDpV5OKlBS6/qJdjZ8Y4XSyzYVUfvYUsh08VyZix4eI+RsaqHDszyprlPaxeWuDo6TGK5SrrV/WRMRgYGqU3n+Xyi3oZKlYYPFvi0hU9rOjNc/T0KOVawPpVfVRqAUeGRlnem+OylUsYHBnj1LkKl1/Uy5J8lkOnwkzjFRf3ca5U48jpIquX9nDJih6Onh5leLTKhov7yGXD8f6eXJYrV/dx6lyZo6dHuWzlEi5eVuCFwXOMVmq88pJl1ALnwOAIK5bkueLiPgaGRjl2ZpRNa5ZxUV+eZ48NUw2cay5bwelihX3Hhrl8ZS9XX7KM518e4eXhMbZEP4cnDp2mkMvw2vUrOXiiyBOHhnj1ZSt41aXL+F7/SU6MlPjpzWsoVwMe2vsSa5b18NZrLmXngZPsfOEUb37VGtav6uN/fHs/Z8cq/Ls3X0X/yyP85RNHuOLiPm65YQN/9E8HGCpW+JPvHeSivgLf+VH4JPj4oSEee3GIH7t0Od989jjf/tEga5f38N7XrefefzqAA2+95hLy2QyDZ0u86eo19b+XXObCqwPimqx5NLswtf3X2bEKR06PcnKkTLkW1Lc4GipWKGQzrFySZ7RS5VypxvLeHD25LMNjFQJ3Vi7JUwuckbEqPfksS3uynCvVKFcDlvXkyGaMkVKVjIVbHVVqAcVyjd58lt58hmK5RrXm9BWymEGxXCObMZYWcpSrAWPVGkvyWfLZDMVylcChr5DFHUYrVXKZDL35LKVq+DV781lyWaNYrmFAXyH8mqVqjUI2SyGXYaxSoxo4S/Lh1xyt1MiYsSSfpVILGKuE7ctnM4xWatQCn/A1s5kMS6KvWaoGLEl8TXdY2pOlWnOK5RqFXHjtaKVGpRZemzHj7FiFTPR9VmoB58pVluSz9OazFMtVKjWvL6Q7PFYhn82wrCdHsVxjtFxjaU92/OcQOCuW5KnUAk4XK/Tms6xckufMaIVzpSqrlhYoZDO8PDyGGVyyvJdz5SrHz5a4aEmeVX0FXhoeY6RUYd1FYR968GSRnlyGDRf38fLwGIdPFVm/qo81ywo8c2yYkVKNH1+3gnOlGo8fGmLNsgKvuXwluw6eYu/RYd541WpWLyvwwO7DVGrOe35yPTtfOMVfPjHAlstW8HPXXsY9D/dTLNf48u4BXjozRl8hy7lSlV/9wk4yZrx+4yrOjFbYdfDUBWe+4xmGm9Ys5S2vvoQfvHCSj2/fy1VrllKqBtyx7QkqtTAQ+9unjvIbP3M1f/vUUQ6dLPIrP3Ul11y2nO1PHuWivgI3/8TlHDszxtNHznDtupW86tLlPH3kNCOlGtdfcREZM549NsyqvgKvvHQZL58Z46XhMa5c3ceqvgKHThVxhytW91GuBrx0ZoyVfXnWLuvh5Lky50pVLlneQyEX9p0rl+TZuvHiC/r+ob0gax1wOPF6AHjDZNe4e9XMzgCro+M7Gu5dd96tbbDjwCleu34lS3tyvOmVqwG45fUbWNqT46brLudLuw7zn37uGi7qK7B9zxFesbKXP/u3N/D57+znv32rn1+4fh2//bbN3HrvDh5+7jgffuerGSpW+Nx39rOqL8+Hbnw1f/GDQ9z1tX1svmQZP//ay/mf33uBwOGnrrqYI6dH+e0v7SGfNa5dt5I/fuQFasEBVvTmWNqT4xv7XgbCX7ShYpnPfns/AMt7c3wpqhmLMwO1oB8Ia120gXm6mUFylLk3n6mnwTMGPbksX4leX9SXp1iucf+uw2QMLr9oCZ99eD8OXL6ylzXLerj7758jmzHeeNVq+gdHuPvvn+Pylb389E+s5Rv7XmasUuPd162jGgR8/aljvGJlL7fecAXf3x8uFPju69axflUfv/bGjYxVaqzqC/+z/s23bu749x5nwmY6nbuLUtt//eXjR/j49r2d+nSyyGQzRi36z8KAlUvy9f9zVvXlyWaM3/3qU+QyxtYoEfHph55j4+o+rt+wigd/eIzAnX//5qsZHq3wZzteZOsVF7G8N8/PXfsKfuzS5Vy2cskFtfHSFWGQtfXKVSzrybHlshU889JZfu7ay6jWAu595AArevP8u5++im/se4n/+s3nWbOsh5uvW8cXd7xILXA2rVnKvqPDfP2pcHhx5ZJ8vX+F2fs/82e3XNqRIMumq0kys/cC73D3/z16/avADe7+HxLX7I2uGYhe7yd84rsLeNTd/zw6/gXgQXf/asPXuB24PXr5Y0AaF71aA5zodiMmobbNXFrbBelt22y260p3X9vpTzoX/Vd0bj70Ya2k9XetXfO9/TD/vwe1f4r+q51M1gCwIfF6PdA4RSC+ZsDMcsBK4FSb9+Lu9wL3ttGWrjGz3e6+tdvtaEVtm7m0tgvS27a0tmsas95/wfzow1qZpz/Tuvnefpj/34PaP7V2cv67gM1mtsnMCoSFoNsbrtkO3BZ9/B7gWx6myLYDt0SzdzYBm4EfdKbpIiLTUv8lIl0zbSYrqlG4A3gIyAL3ufteM7sL2O3u24EvAF+MCkNPEXZkRNc9QFhkWgU+4O61WfpeREQmUP8lIt00bU2WhMzs9mhIIHXUtplLa7sgvW1La7vk/M33n+l8bz/M/+9B7Z/m8yvIEhEREem8eTMPW0RERGQ+UZA1DTP7z2Z2xMz2RG8/lziXii03zOx3zMzNbE302szsv0Vte8rMfnKO2/OJ6OvuMbN/MLPL09CuqA2fNrNno6//V2Z2UeJc136eZvZeM9trZoGZbW041/XfM5tmaxqZX8zsP0Q/z71mdnfieNd/12YibX1fu9LaD83EfOwTzGyDmT1sZs9Ev/u/FR2/2My+YWbPR+9XdeyLxlt76K31G+FK0L/T4vgW4EmgB9gE7AeyXWjfBsKi3heBNdGxnwP+jnCNup8Cds5xm1YkPv5N4HNpaFfUhp8FctHHvwf8Xhp+nsA1hOsrfRvYmqbfM8KC8f3AVUAhas+Wuf7Z6a1jP89/Afwj0BO9viR63/XftRl+H6nr+2bQ9lT2QzNo/7zsE4DLgJ+MPl4O/Cj6N78buDM6fmf88+jEmzJZ56++5Ya7vwDEW27Mtd8HfhdIFtfdDPyZh3YAF5nZZXPVIHcfTrxcmmhbV9sVte0f3D3eGGsH4dpHcdu69vN092fcvdUClmn4PatvTePuZSDemkbmp98APuXhdkG4+/HoeBp+12YidX1fu9LaD83AvOwT3P2Yuz8efXwWeIZwF4ebgT+NLvtT4N2d+poKstpzR5TWvS+RRmy1XUfHttxoh5ndBBxx9ycbTqWhbZ80s8PAvwY+lpZ2Nfi3hE+9kL62xdLQrjS0QTrnVcBPm9lOM/uOmb0+Oj5vfs5p7vvOw3zohxrNl3ZOysw2AtcDO4FL3f0YhIEYcEmnvk47K74veGb2j8ArWpz6CPA/gE8QPi19Avj/CP8oWu2Q2/GpmtO07T8Rpp2bbmtxrKNtm6pd7v437v4R4CNm9mHgDuDjc9GudtoWXfMRwrWP/ld822y3rZ12tbqtxbG5nhKchjbIDEzTb+SAVYTDaa8HHjCzq0jZzzmtfV+70toPdch8aWdLZrYM+Crw2+4+bLO44b2CLMDd39bOdWb2R8DXopdtb7lxISZrm5ldSzhm/2T0C7IeeNzMbpiLtrX7bwZsA75OGGR19d8sZma3AT8PvNWjQfi5aNsM/s2S5uTfbB60QWZgqt81M/sN4C+j3/0fmFlAuH9bqn7Oae372pXWfqhD5ks7m5hZnjDA+l/u/pfR4ZfN7DJ3PxYNLx+f/DPMjIYLp9Ewnv8LwA+jj7u65Ya7P+3ul7j7RnffSPhL/5Pu/lLUtl+LZtr8FHAmToXOBTPbnHh5E/Bs9HFX2xW17UbgQ8BN7l5MnErrFippaFc7W9PI/PHXwFsAzOxVhIXLJ0jH79q00tz3tWse9kON5mWfYGFU/gXgGXf/TOJUcmut24DJRhZmTJms6d1tZtcRpkIPAv8eUr/lxoOEs2z6gSLwb+b463/KzH4MCAhn/rw/Je0C+EPCmTvfiJ6Cd7j7+7v98zSzXwD+O7AW+LqZ7XH3d3S7XTD51jRz2QbpqPuA+8zsh0AZuC3KpHT9d60D0tDHtCOV/VC75nGf8CbgV4GnzWxPdOw/AZ8iHDZ/H3AIeG+nvqBWfBcRERGZBRouFBEREZkFCrJEREREZoGCLBEREZFZoCBLREREZBYoyBIRERGZBQqyZM6Z2bcbd5c3s982s8+a2d+b2Wkz+9pk94uIdMsU/deDZvaome2NtmH7pW61UdJD62RJN/wF4eJ1DyWO3QL8X4QLI/YRrUcmIpIyk/VfHwKOuvvzZnY58JiZPeTup7vRSEkHZbKkG74C/LyZ9UB9o87Lge+6+zeBs91rmojIlCbrv/7J3Z8HcPejhFuzrO1SGyUlFGTJnHP3k4RbRdwYHboF+JJrZVwRSbl2+q9oH8UCsH/uWyhpoiBLuiVOuRO9/4sutkVEZCYm7b+i/W6/CPwbdw+60DZJEQVZ0i1/DbzVzH4SWOLuj3e7QSIibWrZf5nZCuDrwEfdfUc3GyjpoCBLusLdR4BvE25WqyyWiMwbrfovMysAfwX8mbt/uXutkzRRkCXd9BfATwD3xwfM7BHgy4RPiQONU6VFRFKisf/6ReDNwK+b2Z7o7bqutU5SwVRrLCIiItJ5ymSJiIiIzAIFWSIiIiKzQEGWiIiIyCxQkCUiIiIyCxRkiYiIiMwCBVkiIiIis0BBloiIiMgsUJAlIiIiMgsUZImIiIjMgly3G9BozZo1vnHjxm43Q0Tm0GOPPXbC3dd2ux2doD5MZHGZqv9KXZC1ceNGdu/e3e1miMgcMrMXu92GTlEfJrK4TNV/abhQREREZBYoyBIRERGZBQqyRERERGaBgiwRERGRWaAgS0RERGQWKMgSERERmQVtBVlmdqOZPWdm/WZ2Z4vz7zezp81sj5l918y2JM59OLrvOTN7RycbLyJQqQWcHCl1uxkiM3KmWGGsUut2M0Rm1bRBlpllgXuAdwJbgFuTQVRkm7tf6+7XAXcDn4nu3QLcArwGuBH4bPT5RKRD/uR7B3nbZ75DEHi3myLStl+691E+9XfPdrsZIrOqnUzWDUC/ux9w9zJwP3Bz8gJ3H068XArEvf3NwP3uXnL3F4D+6POJSIfsOzbMULHCmdFKt5si0pYzoxWefeksA0Oj3W6KyKxqJ8haBxxOvB6Ijk1gZh8ws/2EmazfnMm9InL+BoaKAJwqlrvcEpH27DsaPpefHdODgSxs7QRZ1uJY07iEu9/j7lcDHwI+OpN7zex2M9ttZrsHBwfbaJKIxOJswNA5BVkyP+w7FgdZ1S63RGR2tRNkDQAbEq/XA0enuP5+4N0zudfd73X3re6+de3aBbFHrMicKFVrvDQ8BsBJBVktne/EHTPbaGaj0fE9Zva5uW/9wrT36BkARkoKsmRhayfI2gVsNrNNZlYgLGTfnrzAzDYnXr4LeD76eDtwi5n1mNkmYDPwgwtvtogAHDs9hke5YWWyml3IxJ3Ifne/Lnp7/9y0euHTcKEsFrnpLnD3qpndATwEZIH73H2vmd0F7Hb37cAdZvY2oAIMAbdF9+41sweAfUAV+IC7a86uSIckC4eVyWqpPnEHwMziiTv74gummLgjs6BUrdF/fISMhZksd8esVWWJyPw3bZAF4O4PAg82HPtY4uPfmuLeTwKfPN8GisjkDkdF76BM1iRaTb55Q+NFZvYB4INAAXhL4tQmM3sCGAY+6u6PzGJbF4UfvTRCNXB+fN0KfnhkmFI1oDevlX1kYdKK7yLz2MBQkWzGuGxlL6cUZLVyIRN3jgFXuPv1hAHYNjNb0fKLaPJO2/YdC+ux3rBpNaDid1nYFGSJzGMDQ6NcflEva5f3aAmH1s574k60vt/J6OPHgP3Aq1rdpMk77dt7dJieXIbhaF23v9h5qMstEpk9CrJE5rHDp4rkMxnGKmGdyzb9h9XovCfumNnaeIcKM7uKcOLOgTlp9QJ28GSRNct66kOEY1WV6crC1VZNloik08DQKBsu7iMInMGz2r+w0YVM3AHeDNxlZlWgBrzf3U/N/XexsJw4W2JZT46efPiMP1YJutwikdmjIEtknhqr1Dh+tsRr169ktFzjXFkZgVbOd+KOu38V+Orstm5heXrgDGbw4+tWTnrNyXMl1q/qozcXZbK0SbQsYBouFJmnjpwOl29Y1VdgaU+OcjWgUlNWQLrnE1/fx+9+5alJzweBc3KkzLKeXH24sFTV76wsXAqyROapeI2si/oKLC2ESemislnSRcOjFZ59aZhiufWMweGxCtXAwyArFw8X6ndWFi4FWSLz1ImoBmtFb46+njArcE7blEgXjZSqBB4OG7ZyYiT8nV3ak6OnnslSkCULl4IskXnqdDQFvq+Qq2eyzk2SQRCZC3GQ/8Th0y3PnxgJlxlZ1pMjmzHyWVPhuyxoCrJE5qkzxTJm0JPP1DNZxZKyAtI956Lfvz2HJguywkzWst7woaA3l9VwoSxoCrJE5qnToxVWLsmTMVMmS7quXA0oRxMvnjg81PKak4lMFoQPCCp8l4VMQZbIPHW6WGFVXwGAJYUsxngmQWSuxcXuV67u4+XhEsfOjDZdc2KkRMagrxBmXnvzymTJwqYgS2SeGiqWWbkkD0DGjCWFrDJZ0jUjUT3WP3/lGgCe6Zer2wAAIABJREFUaDFkeGKkzMVLC2Qs3FKyJ6dMlixsCrJE5qkzoxUu6svXXy/tyVHU7ELpkjiL+vqNF1PIZnj6SPMMwxMjJdYs66m/ViZLFjoFWSLz1OlihYuWJIKsQlarvkvXxJmslX15Vi3Nc2qkecPyEyMlVi8r1F/35rLKZMmCpiBLZJ46XSxzUd/4f1h9hdyki0CKzLb4d29ZT47lvXmGxypN15wcKU/IZPXkM8pkyYKmIEtkHqoFzvBYtV6TBdCbz1DSmkPSJfEaWUsLOZb35jg71hzwnxgpsXrpxOHCUjUgCHzO2ikylxRkicxDw9FCpMmarJ58ljGtni1dMhLVZC3rybGiN8/ZhkxWsVylWK6xZvl49rUn2lpnRBlYWaAUZInMQ/Fq76v6GupbKsoKSHfUM1k92ZaZrHiNrMbCd6Bl1ktkIVCQJTIPDRXD/7BW9k0cLnS0IKl0x0g9yIprsib+Hsarva9Z1iKTpSBLFigFWSLz0JliNFyYrMnKhVmBES3jIF1wrlQlmzG++tgAA0NFThfLbNt5qH7+xJSZrOYieZGFQEGWyDx0ejT8Dys5u7AnH/45a+hFuqFYrrG0kMXM6M1nqQZONRifiHEyymStbhVk6cFAFqi2giwzu9HMnjOzfjO7s8X5D5rZPjN7ysy+aWZXJs7VzGxP9La9k40XWaxOt8pkKSvQUhv91/vN7Omoj/qumW1JnPtwdN9zZvaOuW35/DJSqtb3JOyNhgHHErNd4+HC1Uubhwv1YCALVW66C8wsC9wDvB0YAHaZ2XZ335e47Algq7sXzew3gLuBX4rOjbr7dR1ut8iidrpYwQxWTBgu1H9Yjdrsv7a5++ei628CPgPcGAVbtwCvAS4H/tHMXuXumsLZwrlSlaVxkBUF/KXEGljHzoyxqi9fP5e8TjVZslC1k8m6Aeh39wPuXgbuB25OXuDuD7t7MXq5A1jf2WaKSNKZ0QorevNkM1Y/1qOZWq20038NJ14uBeLpmTcD97t7yd1fAPqjzyctjLQIskYTQdbR06NctnLJhHvGHwyUfZWFqZ0gax1wOPF6IDo2mfcBf5d43Wtmu81sh5m9+zzaKCINwtXe8xOOaTp8S231X2b2ATPbT5iF/82Z3CuhMJMV/g7G9YHJ4cJjZ8a4/KKJQVY+l8HQZA1ZuNoJsqzFsZYL8ZjZrwBbgU8nDl/h7luBXwb+wMyubnHf7VEgtntwcLCNJoksbkMN+xZCuIQDKCvQoK3+y93vcfergQ8BH53JvaA+DOLC97gmKwy2xhoyWZdf1DvhnowZhVxGQZYsWO0EWQPAhsTr9cDRxovM7G3AR4Cb3L0UH3f3o9H7A8C3gesb73X3e919q7tvXbt27Yy+AZHF6PRohZWJmYUAhayyAi201X8l3A/EGfe271Uf1lD4HtdkRTsQjJSqDI9Vm4YL42tVkyULVTtB1i5gs5ltMrMCYSHohFmCZnY98HnCAOt44vgqM+uJPl4DvAlIFpyKyHk4Uyw3ZbLMjJ58RsOFE7XTf21OvHwX/P/t3XuU3Hd53/H3MzM7sxftSqurrZslYxtsYyKDbDg4UNrYxiSpDSk0BnJqGk4d2vi0aZom7qEHWlNaEtqSNJAGSJzQJMI40KRKEBcD5pIYyZKN5PtFlu3V6mLJ0l6k3dmZnZmnf/x+sxqtZndnd2Z2fr/Zz+ucPZrL77f77Gouzzzf5/v98nx4eSdwu5llzGwrcDnw8CLEHEuVje9dHeVKVjBceGw4C3BBJQtQJUva2pyzC929YGZ3Ad8CksC97v6kmd0D7HP3nQTDg8uAvzQzgAF3vxW4Evi8mZUIErpPTZvVIyILMJydvKAnC4KqwKiGC6fU+Pp1V1iJnwSGgDvCc580s/sJPhgWgF/VzMKZjeWKU0nWuZ6s4M91dGQC4IKeLAia35VkSbuaM8kCcPddwK5pt32s4vKNM5z3EHBNPQGKyPlKJWcke2FPFgS9MKpkna+G169/M8u5nwQ+2bzo2kO+UCJfLLEsbHwv91pNTBbZsWeAvS+dBuDhF0/z/Ctnzzs305FUkiVtSyu+i8TMmYkC7uev9l6W6Uiov0UW3Xi4X2Z3+tzn9s5UgolCMFw4PD6JAX2dF34wyKT0mJX2pSRLJGbKW+osn6mSldNwoSyuciWq3PgOwdB1ebhwJDtJb2fqvHXdyjKpJGOqZEmbUpIlEjPl4cBlnReO9neq8V1aYCwXJFM9MyZZ+aofCiCovmrvQmlXSrJEYmasStWgTNPhpRXKlazyYqQQJPzl2YUjVZYcKcukEozlCrhXXYJMJNaUZInEzFi+/IZ2YZKVUeO7tEC1xD+TCipZ7s5wlcVzyzpTSUp+/hY8Iu1CSZZIzJwNh2aWVVQNyjo7EuSLpfNW2hZptqqN7x1JJgolxvNFCiWfdbgQtEm0tCclWSIxM5abuZKl/QulFc4l/pVJVoLcZJGRbDARY8YkK9yCR31Z0o6UZInETPkTf/WerLAqoDcsWURjVXqyujqSFErOK6PBQqTVFs+FoCcLVMmS9qQkSyRmppqM09V7skCbRMviOlulupoJq6r7Dw/T1ZGsum9hcFzwNqRlHKQdKckSiZmxXIHudJJElTWHNFworTCWK5BK2FRVCoLFSAEOnjjL6y7qrbpGVnCchgulfSnJEomZsXyhaj8WnBsuVCVLFlN5c+hw71rgXMLvwNXr+2Y8V8OF0s5q2rtQRKJhx54Bnjw6Sqnk7NgzcMH9U1UBvWHJIhrLF+lJnz/btZxkdSSNy9b2znhueVixvDSJSDtRJUskZnKTpak+lukyU5UsvWHJ4ilXsiqVq6qXre0lnZr5raZcydJjVtqRkiyRmMkVilMN7tNlVMmSFjhbJcla3tlBKmFcu2nFrOemEkZH0jQjVtqShgtFYiZXKM245lAyYXSnk5zVJtGyiMZyhQuWFOnOpPiPP3fVrFUsADOjJ5PS7EJpS6pkicRMrlA6bxbXdMsyKVWyZFGN5YrnrZFVNleCVbYsk1Lju7QlJVkiMRMkWdWHCwG600ntAyeLarYZr7VYlklpCQdpS0qyRGImXyjOWslKpxLkC6VFjCjazOwWM3vWzA6a2d1V7v91M3vKzB4zs++a2SUV9xXNbH/4tXNxI4+PsVyh6uK4tVqm4UJpU+rJEomRYsmZLPqMswshaH7PKckCwMySwOeAm4BBYK+Z7XT3pyoO+wmw3d3HzexfAr8D/GJ4X9bdty1q0DEUDBfWkWR1pjg9lm9gRCLRoEqWSIyUK1SzDReqknWe64GD7n7I3fPAfcBtlQe4+4PuPh5e3Q1sXOQYYy1fKJEvllhWpSerVurJknalJEskRnKFoNdqtuHCTCoxdZywAThccX0wvG0mHwa+UXG908z2mdluM3t3MwKMu7Eq+xbOl3qypF1puFAkRsrDgLPN2kqnElpz6JxqG+Z51QPNfgnYDvyDips3u/tRM7sU+J6ZPe7uL1Q5907gToDNmzfXH3WMlFdqrzfJUk+WtKOaKll1No7eYWbPh193NDJ4kaUmV8NwYUbDhZUGgU0V1zcCR6cfZGY3Ah8FbnX3XPl2dz8a/nsI+D5wbbUf4u5fcPft7r59zZo1jYs+BsZyQdW0rsb3zhTj+SLFUtX8VyS25nxW1NM4amYrgY8TfDp04JHw3KFG/yIiS0Fucu7hwrQa3yvtBS43s63AEeB24AOVB5jZtcDngVvc/UTF7f3AuLvnzGw1cAPBa5uEduwZYODUGAB7XzrNSHZhi+CWFzI9myvMuNCuSBzVUsmqp3H0ncAD7n46TKweAG5pTOgiS89UJWvW2YWqZJW5ewG4C/gW8DRwv7s/aWb3mNmt4WGfBpYBfzltqYYrgX1mdgB4EPjUtA+XQmV1deEtvuUkS0OG0m5qqe9Waxx98yzHVzaOzrfpVERmUctwYVqN7+dx913Armm3fazi8o0znPcQcE1zo4u/WvoE57Ks81wlS6Sd1JJk1dM4WtO5S7lpVGQ+ap9dqEqWLI5alhWZS7mSpe2gpN3U8tGjnsbRms5dyk2jIvORr2FoJq0kSxZRLYn/XPrCPqyRrBYklfZSy7NiqnHUzNIEjaPnbS9R0Th6a2XjKEEfxM1m1h82kd4c3iYiC5ArlEiakUrOvuJ7vlDCXTO1pPkaMVy4fnkXAEeGJxoSk0hUzDlc6O4FMys3jiaBe8uNo8A+d9/J+Y2jAAPufqu7nzazTxAkagD3uPvppvwmIkvAxGRxzjezckUhX5x9I2mRRsgVSiQMUolq3SG1WduboSNpHBnKNjAykdaraWGThTaOhvfdC9y70ABF5Jx8oUTnLDMLoSLJKijJkubLhY+z8AP2giQSxsXLuzg6rCRL2ou21RGJkVwNiVM5yVJfliyGfKFYVz9W2foVnRxRkiVtRkmWSIzkCnMPF6YrKlkizZYrlOrqxyrbsKJbw4XSdpRkicRIUMmaa7gwOXWsSLPla3hM1mJDfxevnJnQhwNpK0qyRGIkNzn3G5oqWbKYahnCrsXGFV24wyujmmEo7UNJlkiM5ArFefRkadV3ab5ahrDnsmPPAM8cPwPAlx56iR17BhoRmkjLKckSiZFcoUR6jtmFqmTJYqplCLsWK7qDBUmHxyf5u+dP8i/+z766v6dIq9W0hIOItN7weJ5cocSKcHXsmagnSxZTvlCadcPyWi0PH9dD2TyPvjzESHaSfIOa6kVaRY9ekZg49OoYAGuWZWY9TpUsWUyN6snqSCbozaR45tgZhsYnKTkMnB5vQIQiraMkSyQmDp0MkqzVcyRZ6smSxVIolSiWvGHVpuXdHeetlfVi+MFCJK6UZInExKGTZ0kY9PekZz0urcVIZZHkJ+fesHw+VnQHj+2L+joBeElJlsSckiyRmDh0coyVPRmSc+wRpxXfZbGUH2ONSrL6w76sN13ST393x9QQuUhcqfFdJCZefHWM1ctmr2KBKlmyeHLF4DGWbtAemWv7OkmacdX6Po6NZFXJkthTJUskBool58VTY3M2vcO52YVqfA+Y2S1m9qyZHTSzu6vc/+tm9pSZPWZm3zWzSyruu8PMng+/7ljcyKMvPxn0/TWqkrVt0wr+3c1X0N+dZsvqHvVkSewpyRKJgaPDWfKFEqt7a0my1PheZmZJ4HPAu4CrgPeb2VXTDvsJsN3d3wB8Ffid8NyVwMeBNwPXAx83s/7Fij0OGj1cmEzYVF/Wpat7OD46wXi+0JDvLdIKSrJEYqDcmzLXzEKAdFJLOFS4Hjjo7ofcPQ/cB9xWeYC7P+ju5bUCdgMbw8vvBB5w99PuPgQ8ANyySHHHQjnJasZaVltW9wDw0qtaxkHiS0mWSAwcOnkWoKaerETC6EiaerICG4DDFdcHw9tm8mHgG/M918zuNLN9Zrbv5MmTdYQbL+cqWY3pyaq0tZxkndKQocSXkiyRGDh0cozezhTLMrXNVcmkkqpkBapNxfSqB5r9ErAd+PR8z3X3L7j7dnffvmbNmgUFGkcj2UkAejsbP4dqy6ogyVJflsSZkiyRGHjx1TEuXd2D2ezLN5SlUwn1ZAUGgU0V1zcCR6cfZGY3Ah8FbnX33HzOXcqGxvP0ZlJ0JBv/VtKTSbGuL6MkS2JNSZZIDAycHueS8JN9LTKphCpZgb3A5Wa21czSwO3AzsoDzOxa4PMECdaJiru+BdxsZv1hw/vN4W0SGhrLz7k4bj02rOji2Eh27gNFIkpJlkjEFUvO0eEsm1Z21XxOUMlSkuXuBeAuguToaeB+d3/SzO4xs1vDwz4NLAP+0sz2m9nO8NzTwCcIErW9wD3hbRIaGs/T3z37huX16O3s4GxOFVmJLy1GKhJxx0cnKJScjf3deNWOoAupknWOu+8Cdk277WMVl2+c5dx7gXubF118FYolRrKTTa1kLcukGBzS7EKJL1WyRCLu8OngTWZTf3fN56iSJc12bGSCksPK7uYkWTv2DPDK6AQnz+TYsWegKT9DpNlqSrJqWDH57Wb2qJkVzOy90+4rhiX4qTK8iNRuKsmax3ChZhdKsx0OK0wrmpRkQVCRndDjWGJszuHCihWTbyKYbbPXzHa6+1MVhw0AHwJ+o8q3yLr7tgbEKrIkDQ5lMYOLl8+jJyup2YXSXIOng4b0lU0cLsx0BB8WSrWOk4tETC2VrFpWTH7J3R8D9JFDpMEOD41zcV/nvFbVznSoJ0ua6/DQOAYs72pe43tnSrsXSLzV8qo93xWTp+sMV0LebWbvnld0IsLg6SwbV9bejwXlSpbemKR5Dp8eZ3l3B8lEbWu3LUSmI1hJfmJSVVmJp1pmF9a86vEMNrv7UTO7FPiemT3u7i+c9wPM7gTuBNi8efM8vrVI+xscGuctr1k1r3PKwywizXJ4KEt/E/uxoHKzcz2WJZ5qqWTVteqxux8N/z0EfB+4tsoxS3JLCpG55Asljo1OzGtmIaiSJc13+PR402YWlpX3RNRjWeKqliRrzhWTZxKulJwJL68GbgCemv0sESk7OpzFHTbNc7gw06EkS5pnYrLIiTM5VvQ0rx8LoLMjrGRpuFBias4kq5YVk83sOjMbBN4HfN7MngxPvxLYZ2YHgAeBT02blSgisxgcCmZwbeyvfWYhaHahNNffPf8q0Lw1ssrKlSwt4yBxVdOK7zWsmLyXYBhx+nkPAdfUGaPIkvW1RwYBePTlIQ6drH2jXM0ulGb5ve88z+9+9zm2rOrm8nW9Tf1ZGVWyJOa04rtIhA2N50kY9M1zmnwm7MlyrS8kDXTizASf+c5z3HL1RXz9X7+NZZnm7szWqZ4siTklWSIRNpYv0JNJkbD5TZMvT33PF/XmJI3z+989CMDmld38v/01z39asPLacBMa+paYUpIlEmH5Qol0cv5P0/I5GjKURhocGicxz90H6pFMGB1JIz+px7HEk5IskQibLPq8Vnovm+plUZIlDTQ4lGXdPHcfqFcmlVTju8SWkiyRCMsXS3TMs5K1Y88APxkYBuD+vYfZsWegGaHJEuPuHB4an/dM13plUpopK/GlJEskwhY6XJgKtzoplNT4Lo3x0qlxJiZLbJznwrj16uxIktNwocSUkiyRCJssluhIzn9vuFSYmCnJkkY5cDiojraikqXGd4krJVkiEZYvlOhYQP/LVCVLswsxs1vM7FkzO2hmd1e5/+1m9qiZFczsvdPuK5rZ/vCrpp0u2tX+w8N0JI21vZ2L+nMzqmRJjDV3kRMRqctksb7hwuISr2SZWRL4HHATwT6se81s57SdJwaADwG/UeVbZN19W9MDjYHHBodZv6KLZGL+ldV6qCdL4kyVLJEIyxcXWMkKE7PJ4tJOsoDrgYPufsjd88B9wG2VB7j7S+7+GKByySwOD2VZsyyz6D83SLL0XyPxpCRLJMImi15nJWvJvzltAA5XXB8Mb6tVp5ntM7PdZvbumQ4yszvD4/adPHlyobFGVrHknDqbo7dz8Qc/yo3v2r1A4khJlkhEFYoliiWf9xIOAKmwWV6VLKqNbc3nj7LZ3bcDHwB+18xeU+0gd/+Cu2939+1r1qxZSJyRdmosR8lhWef8tndqhEwqQdFd1SyJJSVZIhGVDTfFTS9gdmFSPVllg8CmiusbgZr3g3H3o+G/h4DvA9c2Mri4ODGaA6C3yXsVVlPeIupsrrDoP1ukXkqyRCIqmw+SrIX0ZHUkyks4LPlP/3uBy81sq5mlgduBmmYJmlm/mWXCy6uBG4CnZj+rPZ08GyZZrRguDB//ZyeUZEn8KMkSiajxfLmSNf+naTKpxUgB3L0A3AV8C3gauN/dnzSze8zsVgAzu87MBoH3AZ83syfD068E9pnZAeBB4FPTZiUuGSfPlJOsVgwXqpIl8aUlHEQiqjxcuJCerHIlSz1Z4O67gF3TbvtYxeW9BMOI0897CLim6QHGwLkkqxXDhcFj+YwqWRJDqmSJRNRUJWsBw4Xlc/JaX0ga4OSZYGbhQhL+emXKw4WqZEkMKckSiaiJOipZyYSRSphWypaGOHFmgjW9i79GFkBnOFw4piRLYkhJlkhE1VPJgnA7Ek17lwY4eSbH2hYlWVPDhUqyJIaUZIlE1LmerIVtY9KpjXWlQU6cybFmkfcsLJtqfFdPlsSQkiyRiMrmgzeVhcwuhKACoOFCaYRWVrI6kkbC4MzEZEt+vkg9lGSJRFS2jiUcIKgAaGNdqdfZXIHxfLFlPVlmRiaV1OxCiaWaXr3N7BYze9bMDprZ3VXuf7uZPWpmBTN777T77jCz58OvOxoVuEi7G59c+GKkoI11pTHKyze0qpIF0JVOMqpKlsTQnK/eZpYEPge8C7gKeL+ZXTXtsAHgQ8COaeeuBD4OvBm4Hvi4mfXXH7ZI+8vmixjnNnuer041vksDnBidAGhZJQugqyPJSFZJlsRPLR+RrwcOuvshd88D9wG3VR7g7i+5+2PA9Ff0dwIPuPtpdx8CHgBuaUDcIm0vmy/SkUpgtrAkK5NKTC0DIbJQ5S111rao8R2gsyPBqJIsiaFakqwNwOGK64PhbbWo51yRJW18sljX4o9BT5YqWVKf8ubQra5kjaonS2Kollfwah+ja92ro6ZzzexOM9tnZvtOnjxZ47cWaW8T+SLpBS7fAMGn/2LJKRSVaMnCnTyboyNprOha/H0Lyzo1XCgxVUuSNQhsqri+ETha4/ev6Vx3/4K7b3f37WvWrKnxW4u0t/F8fZWs8iKmE6pmSR1OjOZYvSxDYoG9gY3Q1ZHUcKHEUi2v4HuBy81sq5mlgduBnTV+/28BN5tZf9jwfnN4m4jMITtZXPBq73BuO5K8kiypw4kzE6zta10/FgSzC3OFknoMJXbmfAV39wJwF0Fy9DRwv7s/aWb3mNmtAGZ2nZkNAu8DPm9mT4bnngY+QZCo7QXuCW8TkTlk66xklbcj0RuT1OOV0Qku6mtdPxYEw4WAlnGQ2EnVcpC77wJ2TbvtYxWX9xIMBVY7917g3jpiFFmSspPFBS9ECue2I1Hzu9Tj+MgEb7l0VUtj6ConWdkCa3tbGorIvGjFd5GIGs8XFrwQKQRLOADkVMmSBcrmi4xOFFjX4uHCciVLze8SN0qyRCIqm6+zktWhxnfQjhX1eCVciLTVSVZX+FjWcKHETU3DhSKy+ILG9zqWcJgaLly6layKHStuIpjtvNfMdrr7UxWHlXes+I1p55Z3rNhOsPTMI+G5Q4sRe6vt2DPAi6+OAfDU0VF2FAZaFktnujxcqCRL4kWVLJGIqncJh3IlKze5pCtZ2rGiDuWkpreztZ/Hz/VkKcmSeFGSJRJBpZKTK5TqGi5MJxMYS7uShXasqEt5eG55CxcihcrZhVr1XeJFSZZIBGXDZvV6KllmRjqVWOo9WU3fsQLad9eK0ewk6WRiahJFq3SEMajxXeJGSZZIBJWTrHoWI4WgArDEhwubvmMFtO+uFaMTBXo7UwvepLyR+ro6NFwosaMkSySCsvn6K1kQLOOwxIcLtWNFHUYnJulr8VBh2fKuDs0ulNhRkiUSQY2qZAVJ1tKtZGnHivqMZifpa3HTe1lfZ0rDhRI70Xj2iMh5xqcqWfUN03R2JJf8tjrasWJh3J0zE4VIVbJePZtvdRgi86JKlkgEjeeDWVT1zC4E1PguC5bNFymUnL7OaCRZfRoulBhSkiUSQRMNmF0IwYKk2lZHFmIkTGiiUsnq6+zQcKHEjpIskQgqDxfW3ZPVsbR7smThzoRrUkWlJ2t5OLvQvdYVOERaT0mWSAQ1bnZhknyhRKmkNyaZn/JyCdEZLkxRcjib04KkEh9KskQi6PRY0ODbHe7ZtlCZVAIHxjVkKPN0eixPwlq/pU5ZOdnTqu8SJ0qyRCLoyHCWvs7U1HYiC1Xev/Cs3phkngaHs1zU10mqzmpqo5S39tGCpBIn0Xj2iMh5jgxl2dDfXff36UwFSdrZnN6YpHalkjM4NN6Qx2CjlBvw1fwucaIkSySCBoeybOzvqvv7TFWychoulNq9dGqMickSmxrwGGwUVbIkjpRkiUSMu3NkOMuGFQ1IssJKlt6YZD4eGxwBYGOEKln9PWkATo1pQVKJDyVZIhEzkp3kbK7QkEpWuXF+WEmWzMP+w8N0JI01vZlWhzJlzbIMZnB8ZKLVoYjUTEmWSMQMDmUBGppkjYzr07/U7sDgMBtWdJFM1LetUyOlUwlW9WR4ZVRJlsSHkiyRiDmXZNU/VNMVJllD46pkSW0miyWePDoaqaHCsouWZziuJEtipKYky8xuMbNnzeygmd1d5f6MmX0lvH+PmW0Jb99iZlkz2x9+/WFjwxdpP0eGgySrET1ZqUSCdCrBsJIsqdFTR0fJF0oNqaQ22kV9nRoulFiZc5U5M0sCnwNuAgaBvWa2092fqjjsw8CQu19mZrcDvw38YnjfC+6+rcFxi7StwaFxutNJVnQ3ZqXt7o4kwxoulBp98UeH6OpIcumaZa0O5QLr+jp55OWhVochUrNaKlnXAwfd/ZC754H7gNumHXMb8KXw8leBnzGz6Azmi8TIkXD5hkY9hbrTSTW+S00OHB7mbx87xr9421aWZaKx0nuli/o6GRqfnNpAXSTqakmyNgCHK64PhrdVPcbdC8AIsCq8b6uZ/cTMfmBmb6szXpG2NzjUmOUbyrrSSYZUyZI5/Pnul/m3X9kfVlHTrQ6nqnXLOwE4MZprcSQitaklyar2cXr6brMzHXMM2Ozu1wK/Duwws74LfoDZnWa2z8z2nTx5soaQRNrXkeFsQ5uOu9MpRtSTJbN4ZXSCP/n7Fzn06hg3Xrmu7u2cmuWiviDJUvO7xEUtSdYgsKni+kbg6EzHmFkKWA6cdvecu58CcPdHgBeAK6b/AHf/grtvd/fta9asmf9vIdImzkxMMpKdZEMDm46XeiVLE3dm5+584Iu7GTg9znu2beDNW1e2OqSqduwZmOrH+tojg+ynv8RUAAATeElEQVTYM9DiiETmVkuStRe43My2mlkauB3YOe2YncAd4eX3At9zdzezNWHjPGZ2KXA5cKgxoYu0n/LMwkbO7OpOJxnJTlIqTS9At7+KiTvvAq4C3m9mV007bGriDvAZgok7ZS+4+7bw6yOLEvQiOzYywQsnx7j5qou4buvKhvUCNsPU1joTqsxKPMyZZIU9VncB3wKeBu539yfN7B4zuzU87I+BVWZ2kGBYsPxp8e3AY2Z2gKAh/iPufrrRv4RIuzgy1LjlG8q6O5KUHM5MFBr2PWNEE3fmsP/wMACbV0ZvXazpMqkE6WRC20RJbNQ0fcTddwG7pt32sYrLE8D7qpz3NeBrdcYosmQ0ciHSsu508DQfzuZZ3qBlIWKk2sSdN890jLsXzOyCiTvAKPAf3f1HTY530e0/PEw6meDisKk8ysyMvq4UI0vzA4PEUPTm6IosUTv2DPCdp14hlTC+/eTxhg3bVK76fsmqOQ5uP42YuHPKzN4E/LWZXe3uoxf8ELM7gTsBNm/eXGfIi2v/wDBXre8jlYzHBiB9nR2qZElsxONZJbJEDI3nWdGdbmhfzNQm0Uuz+b3pE3fC+2M5eadQLPH4kRGu3byi1aHUrK+rQz1ZEhtKskQiZDg7SX+Dh/S6ppKsJfnGpIk7s3j2lTNkJ4ts2xSjJKuzgzPZAiVfehM5JH6UZIlEyNBYvuELQU71ZC3BSpYm7szuJwNB0/u1m/pbHEnt+rpSFN0Zz2vVd4k+9WSJRES+UGIsX2x8JStcWHKpbq2jiTsz2394mJU9aTatjN5m0DNZ2RN8CDkxw4Kke186zWvWLJs6TqSVlGSJRES50tToSlYyYfR2ppbqcKHMwN156OCrXLelP9JrY013ycoeDDj06tgF93336Vf48Jf20ZNO8ss/vZV/8zOXx6ahX9qTkiyRiChXmhpdyQJY0d2xJIcLpbodewY4Opzl6MgEb7l0VaxWT+9KJ1m/ootDJ89Pskayk/zbr+xnbW+GtX2d/P73DnJseIL//k9/qkWRiqgnSyQyhppUyQLo704zpEqWVHjm+CgGvPai3laHMm+Xru7h8NA4E5Pn+rI+9Y2nOTNR4L1v2sj7r9vE6mUZHn6prVroJIaUZIlExPD4JEkLhvYabXlXx5LtyZLqnj52ho39XfR2xm+B2kvX9FAs+dRehs+9cob79h7mhstWs7G/GzPj+i39DJwe59njZ1ocrSxlSrJEImJoPFiRPdGE/pj+7rSGC2XKaHaSI8NZrry4r9WhLMiWVT0kDH78wikAfu87z9OTTvGOK86tUXbt5n6SCePLD8dnKFTaj5IskYgYHp9kRZO2vQl6slTJksAzYXXndRfFM8nKdCTZsKKL7z93gh88d5KvP36MX75hC92Zc1XgnkyK16/v42uPDpLVcg/SIkqyRCJieDxPfxP6sSDo8xqdmKRY0gKOS12x5Dz0wqus6c2wri/T6nAW7PJ1vTxxZJQ77n2Yzo4Ey7sufO5ct3UlZyYKfP3xYy2IUESzC0UiYXRikjMThabMLARY1ZPGHU6dzbG2L/obAUvz/M2Bo5w4k+P26zbFaumG6f7R69ZyxdplHB/Nsbo3PbWzQaWtq3q4dE0PX354gPe+aeN59xVLzjefOM4Nl61qymQTEVAlSyQSvvn4cRy4Yl1zZnqVv+9Txy7Y21iWkMliid/9znNcvLyT129Y3upw6pIwY/OqHq7fupJLVy+reoyZ8YHrN/PIy0MXNMD/3nef51d3PMqN//OHfPOJ44sRsixBSrJEIuCv9x9hVU+aDSuas/L21RuC3psnjow05ftLPPzZj1/mpVPj3HjluqZMsIiiX3jjRtLJBDv2vDx120MHX+X3v/c8N165jrW9GT7y54/wwFOvtDBKaVcaLhRpseMjE/z40Cn+0WvXNm345m8PHGNVT5pvPHGclT0ZPvDmzU35ORJdL58a49PfepZ3vHYNr4vh2lgL9c0njnP1+j7+fM8AqWSCnnSKP/77F1ndk+GGy1aRNOMr+w7zW197jJ/a+DYNp0tDqZIl0mI7DxzBHbZtWtHUn7N+RRdHh7NN/RkSTaWS81tfe4xUwvhvv3BNrHuxFuLn37CeVT1p/nz3y3zhRy+QNPjgWzaTSSVJJRPcdNU6zkxM8r7P/5jPfu9gq8OVNqIkS6SF3J3/++gRfmrTClYta+5Mrw0ruhgan2Q8V2jqz5Ho+bWv7Gf3odPceNU6HnzmZKvDWXRd6SQfeusWMqmgkvUrb38Na3vPVazW9nbynms3cHQ4y2e+8xy/+dUDPPjsCQrFUgujlnag4UKRFtp/eJhnjp/hv7z79U3/WevDfq+jIxNN/1kSHYdPj/PNJ45z2dplbL+kv9XhtMyK7jS/duMVJBNGR5VNo7dt6mfr6mV875kTfP2xY9y/b5B/cMUa/uiO7VWPF6mFHjkiLbRjzwDd6SS3bVvf9J+1fnnwyV1DhkvHxGSR3/zqY2Dwnms3LLlhwuk6O5KzJkzLuzp4z7Ub+M1bXsfPXnMxP3juJB/44m7+YvfLM54jMhtVskRaYMeeASYmi/z1/iNs27SCvznQ/MUSuzMp+rs7OKIka0k4dTbHr/zZI+x7eYh/8saNTVvoth11JBP89GWrGcsV+MFzJykUnX+8bT19MdznUVpLlSyRFsgVivzguZNMFp3rt6xatJ+7fkUXA6fHtfJ7m3vk5dPc+tm/57EjI3z2A9fypiU8TFiPm65axz987Vr2Hx7mXb/7I3YfOtXqkCRmakqyzOwWM3vWzA6a2d1V7s+Y2VfC+/eY2ZaK+/5DePuzZvbOxoUuEj/uzucePMh/3fU0P3juJJetXcaG/uasjVXNGzauYCQ7ya4ltM3IUnr9Oj4ywQe/uJv3/eGPGc8X+PANWxnNaqLDQiXMuOmqdfzK2y+lI2m8/4u7+eTXn2JiUnshSm3mHC40syTwOeAmYBDYa2Y73f2pisM+DAy5+2Vmdjvw28AvmtlVwO3A1cB64DtmdoW76xEqS8YLJ8/y4DMnKJScR14e4oGnXuHq9X289TWruWRV96LGcvX6Ptb0Zvjcgwf5uWsuJpFo7x6dpfD6depsjgODw3zt0SN8+8njFIrOGzf383NvuJjOjgu3mpH527yqhw+9dSu7njjGF3/0IjsPHOUPf+lNXLtZFUKZXS09WdcDB939EICZ3QfcBlS+SN0G/Kfw8leBz1rQYXkbcJ+754AXzexg+P1+3JjwRc7n7uG/4fXK28673acuV/8+MJYvMJ4rUnSn5MHx7o4D+UKJsVyB8cki2XyR8XyRbL7AeL7ISHaS4yMTHBuZ4MhwloHT41PfN2HwrtdfxE9ftrolTcgJM95xxRr+8pFB/ujvDrFlVQ8b+ru4Yl0vY7kCQ+OTrO3N0J1OMjpRwN2n+lDGJ4tkUgk6kglKJadQcjqShplRKjlmTP1OpXA4MgJJXKxev9ydkgf76pXcKZacyWKJ02N5To/lOTWWZ3Aoy8ETZ3nhxFmeP3GGofFJALrTSa7bspK3vmY1K3vUf9Vo6VSCd2/bwJUX9fF/Hx3kPX/wEK+7qJdrN/fTnU7Sk07SlU6RsOB5ZgaZjiRrlmXo60yRSBjJhJEwI1VxOZmo+DIjkYBUIkEiAUmzc5fD4yuVrxp2wW3B7ZXH2tRtU+ct8DXIy6+HnHt9Lf/OS31yxXS1JFkbgMMV1weBN890jLsXzGwEWBXevnvauRsWHO00H/yj3Tz68nDwBsi5Fyh3x8xIhP/hUw/6Wb5X+f228k248no15z+Yqz/IZ/x5s73Bs7B+mdl+w4XGND2W2eKeS63PvcoEiSpJ0UyJU1QkDPo6O+jrCr5+7pqLuXp9H93p4OmWTrW2FfING1fw8Eun+a+7npm6zez8v2MqYRTCRCmZsKkkEyCTSpArlKaOSySMfHi9syMRJgbOH/2z7dx41brF+aVmFtnXr/seHuA//81TQRJfcoo+e+JfqTudZE1vhsvWLmNNbyfr+jJsXd1DKqE222Z77UW9/NqNV3BgcJgDh4f52wNHyRVLTBZKC3zlbr1zyVr1ZMydivfZub9Xovz+SznxalbkzfPOqy/i926/tu7vU0uSVe3PM/3PPNMxtZyLmd0J3BlePWtmz84Qy2rg1Rnua7UoxwbRji/KsUG044tsbDf9NlB7fJc0KYymv37BvF7DFuqCv+PTDf4BiySyj9d5aoffox1+B2jS7/Es8L/eX/PhM75+1ZJkDQKbKq5vBI7OcMygmaWA5cDpGs/F3b8AfGGuQMxsn7tvryHmRRfl2CDa8UU5Noh2fFGODSIRX9Nfv6D217CFisDfsSH0e0RHO/wOEP3fo5ba8l7gcjPbamZpgkbQndOO2QncEV5+L/A9D8ZzdgK3h7N3tgKXAw83JnQRkTnp9UtEWmbOSlbYo3AX8C0gCdzr7k+a2T3APnffCfwx8GdhY+hpghcywuPuJ2gyLQC/GrWZOSLSvvT6JSKtVNOK7+6+C9g17baPVVyeAN43w7mfBD5ZR4yVmlaOb4AoxwbRji/KsUG044tybBCB+CL0+lWPlv8dG0S/R3S0w+8AEf89zKM2NUtERESkDWi+r4iIiEgTRD7JMrP/ZGZHzGx/+PWzFfdFZssLM/sNM3MzWx1eNzP7X2F8j5nZG1sQ0yfCn73fzL5tZuujElsYx6fN7Jkwhr8ysxUV97X0/9bM3mdmT5pZycy2T7svEo+7ubaLWeRY7jWzE2b2RMVtK83sATN7PvxXy2PXYbbXwqiL0mO1Hmb2kpk9Hv7997U6nlq1y/Nzht8j0s+LyCdZoc+4+7bwaxeAnb/lxS3AH1iwhcaiM7NNBNt2DFTc/C6C2UiXE6yf879bENqn3f0N7r4N+Fug3IcShdgAHgBe7+5vAJ4D/gNE5v/2CeAXgB9W3hiR2Cq3i3kXcBXw/jC2VvlTgr9HpbuB77r75cB3w+tSnwteC6Mugo/Vev3D8O8f2WUDqvhT2uP5+adc+HtAhJ8XcUmyqpna8sLdXwTKW160wmeA3+T8hQpvA/6PB3YDK8zs4sUMyt1HK672VMTX8tjC+L7t7uXda3cTrENUjq+l/7fu/rS7V1tQsuWxhaa2i3H3PFDeLqYl3P2HBDPzKt0GfCm8/CXg3YsalERFpB6rS1G7PD9n+D0iLS5J1l3hkNK9FSXNattlNGzLi1qZ2a3AEXc/MO2uqMT3STM7DHyQc5WsSMQ2zS8D3wgvRzG+sqjEFpU4ZrPO3Y8BhP+ubXE87aDaa2HUxeGxWisHvm1mj1iwyn+ctdPzM7LPi0gkWWb2HTN7osrXbQRDWa8BtgHHgP9RPq3Kt2rKVMk54vso55KX805bjPjmiA13/6i7bwL+ArhrMWOrJb7wmI8SrEP0F4sZXy2xVTttMWKrQVTikAZa4Gth1LXTY/UGd38jwdDnr5rZ21sdkET7eVHTOlnN5u431nKcmX2RoLcI5rHlRb1mis/MrgG2Agcs2AFzI/ComV2/WPHV+rcDdgBfBz5OBP52ZWZ2B/DzwM/4ufVEova3q7Rof7uYxDGbV8zsYnc/Fg5Hn2h1QFG3wNfCqIvDY7Um7n40/PeEmf0VwVDoD2c/K7La4vnp7q+UL0fxeRGJStZspvUKvYegIRkisOWFuz/u7mvdfYu7byF4MXmjux8P4/tnFngLMFIuzS4WM7u84uqtwDPh5ZbHFsZ3C/BbwK3uPl5xV8v/b2cRldhq2S6m1Sq3q7kD+H8tjCX2ZnktjLo4PFbnZGY9ZtZbvgzcTHz+D6ppi+dn1J8XkahkzeF3zGwbQXn5JeBXIBZbXuwCfpagMXoc+OctiOFTZvZaoAS8DHwkQrEBfBbIAA+ElcDd7v6RKPzfmtl7gN8H1gBfN7P97v7OKMQGM28Xs9hxlJnZl4F3AKvNbJCgYvop4H4z+zDBzNuqq6pLzaq+FkZd1B6rdVgH/FX4WpUCdrj7N1sbUm3a5fk5w+/xjig/L7Tiu4iIiEgTRH64UERERCSOlGSJiIiINIGSLBEREZEmUJIlIiIi0gRKskRERESaQEmWLDoz+76ZvXPabb9mZn8Sblex38yeNLOPzPQ9RERaYZbXrz8IL/eZ2REz+2xrIpQoUZIlrfBlggUJK91OsMP6W919G/Bm4G4zW7/IsYmIzGam168vh5c/AfxgUSOSyFKSJa3wVeDnzSwDYGZbgPXAD909Fx6TQY9PEYmemV6//s7M3kSwaOm3WxadRIrexGTRufspgq1obglvuh34iru7mW0ys8eAw8Bvl/cKExGJgplevwg2wv4fwL9vUWgSQUqypFUqS+5TpXZ3P+zubwAuA+4ws3Utik9EZCbVXr/+FbDL3Q+3LCqJHG2rIy1hZsuAQwSfBr/s7q+tcsyfAF93968udnwiIjOp9vplZn8BvI1gr9hlQBr4A3e/u3WRSqvFYYNoaUPuftbMvg/cS1jFMrONwCl3z5pZP3AD8D9bF6WIyIWqvX65+wfL95vZh4DtSrBEw4XSSl8Gfgq4L7x+JbDHzA4QzM757+7+eKuCExGZxfTXL5ELaLhQREREpAlUyRIRERFpAiVZIiIiIk2gJEtERESkCZRkiYiIiDSBkiwRERGRJlCSJSIiItIESrJEREREmkBJloiIiEgT/H/jXTtg1dlBLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the histogram of a variable from the dataset to see the skewness\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(2,2,1)\n",
    "sns.distplot(df['V1'])\n",
    "plt.subplot(2,2,2)\n",
    "sns.distplot(df['V2'])\n",
    "plt.subplot(2,2,3)\n",
    "sns.distplot(df['V3'])\n",
    "plt.subplot(2,2,4)\n",
    "sns.distplot(df['V4'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here in the above variables we can see that the data is skeweed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1        -3.352780\n",
       "V2        -4.743314\n",
       "V3        -2.115044\n",
       "V4         0.671234\n",
       "V5        -0.335423\n",
       "V6         1.213213\n",
       "V7        -1.054441\n",
       "V8        -9.048266\n",
       "V9         0.524853\n",
       "V10        1.046184\n",
       "V11        0.337235\n",
       "V12       -2.187217\n",
       "V13        0.067930\n",
       "V14       -1.913552\n",
       "V15       -0.311223\n",
       "V16       -1.057503\n",
       "V17       -3.526079\n",
       "V18       -0.248354\n",
       "V19        0.116720\n",
       "V20       -1.377751\n",
       "V21        3.490872\n",
       "V22       -0.218690\n",
       "V23       -6.872356\n",
       "V24       -0.540695\n",
       "V25       -0.429101\n",
       "V26        0.567342\n",
       "V27       -2.175241\n",
       "V28       13.803155\n",
       "Amount    13.520470\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for the skewness in each column of variable\n",
    "X_train.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we can see that data is skeweed both positive and negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.44569155, -0.17985939, -0.82537101, ..., -0.21338865,\n",
       "        -0.18593313, -1.44748939],\n",
       "       [-0.1685569 ,  0.70771555, -0.415595  , ...,  0.57666235,\n",
       "         0.28299091, -1.13077718],\n",
       "       [ 1.54055149,  0.05920404, -1.39766213, ..., -0.23217377,\n",
       "        -0.20541154, -0.86502161],\n",
       "       ...,\n",
       "       [ 0.44926405, -0.65653239,  0.44059444, ...,  0.09733236,\n",
       "         0.20682708,  1.18854512],\n",
       "       [ 0.22075551, -0.98861027,  0.05561301, ..., -0.18686459,\n",
       "         0.25017814,  1.56343857],\n",
       "       [-0.45562581,  0.76260283,  0.24868191, ..., -0.11534124,\n",
       "        -1.54276014, -1.31557838]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing powertransform to solve skewness using yeo-johnson transformation\n",
    "pt = PowerTransformer(method='yeo-johnson', copy=False)\n",
    "# Transforming the train\n",
    "pt.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5489728 ,  0.90693893, -0.11880639, ..., -0.10845986,\n",
       "         0.1682697 ,  0.90614999],\n",
       "       [ 0.02900078,  1.26298313, -1.42930631, ...,  0.28579121,\n",
       "        -0.17773486, -0.42121565],\n",
       "       [ 1.44598086, -0.05876374, -0.93258504, ..., -0.04211333,\n",
       "        -0.15847193, -0.39336493],\n",
       "       ...,\n",
       "       [ 0.40868218, -0.26835173,  0.14282805, ...,  0.08737481,\n",
       "        -0.00934433,  0.41315897],\n",
       "       [-1.77970024, -1.85901143,  1.25936891, ...,  1.88347733,\n",
       "         0.26547971,  0.711806  ],\n",
       "       [-2.51620799,  4.30563499, -3.29814821, ..., -3.06702976,\n",
       "         0.72289157,  0.81718011]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming the test data\n",
    "pt.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the histogram of a variable from the dataset to see the skewness\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(2,2,1)\n",
    "sns.distplot(X_train['V5'])\n",
    "plt.subplot(2,2,2)\n",
    "sns.distplot(X_train['V2'])\n",
    "plt.subplot(2,2,3)\n",
    "sns.distplot(X_train['V3'])\n",
    "plt.subplot(2,2,4)\n",
    "sns.distplot(X_train['V4'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1       -0.218659\n",
       "V2        0.348200\n",
       "V3       -0.079351\n",
       "V4        0.018358\n",
       "V5       -0.346900\n",
       "V6       -1.993752\n",
       "V7        0.606021\n",
       "V8        2.389016\n",
       "V9       -0.060698\n",
       "V10      -1.356770\n",
       "V11       0.057088\n",
       "V12       0.165318\n",
       "V13       0.005926\n",
       "V14       0.108003\n",
       "V15       0.009912\n",
       "V16       0.027145\n",
       "V17      -0.825831\n",
       "V18      -0.057166\n",
       "V19       0.016302\n",
       "V20      -0.481587\n",
       "V21      -2.081382\n",
       "V22      -0.019893\n",
       "V23      -0.020900\n",
       "V24       0.123275\n",
       "V25       0.082718\n",
       "V26      -0.023450\n",
       "V27       1.326715\n",
       "V28       1.207900\n",
       "Amount    0.017888\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the squeness of the training data\n",
    "X_train.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we could see that skewness of the variables have been reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5781556"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of training dataset\n",
    "X_train.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "- Build different models on the imbalanced dataset and see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified KFold cross validation with 10 fold\n",
    "folds = StratifiedKFold(n_splits = 5, random_state = 100, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99873329, 0.97491731, 0.95294698, 0.97869706, 0.98620224])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression using cross validation and roc-auc as scoring matics\n",
    "lr = LogisticRegression()\n",
    "scores = cross_val_score(lr, X_train, y_train, scoring = 'roc_auc', cv = folds)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9782993766643253"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean of all the scores of cross validation\n",
    "mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92734781, 0.88379418, 0.88383186, 0.86219323, 0.83068137])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "scores = cross_val_score(dt, X_train, y_train, scoring = 'roc_auc', cv = folds)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8775696886611403"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean of all the scores of cross validation\n",
    "mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97762223, 0.95491768, 0.93284212, 0.93308989, 0.93231947])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "scores = cross_val_score(rf, X_train, y_train, scoring = 'roc_auc', cv = folds)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9461582802192807"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean of all the scores of cross validation\n",
    "mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99727542, 0.98641532, 0.97784962, 0.9831322 , 0.98244412])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "scores = cross_val_score(xgb, X_train, y_train, scoring = 'roc_auc', cv = folds)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9854233356404609"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean of all the scores of cross validation\n",
    "mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building with balancing Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler()\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "X_test_ros, y_test_ros = ros.fit_resample(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "X_test_smote, y_test_smote = smote.fit_resample(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "- Build different models on the balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified KFold cross validation with 10 fold\n",
    "folds = StratifiedKFold(n_splits = 5, random_state = 100, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with Random OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98792407, 0.98852421, 0.98903512, 0.98842404, 0.98850964])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression using cross validation and roc-auc as scoring matics\n",
    "lr = LogisticRegression()\n",
    "scores = cross_val_score(lr, X_train_ros, y_train_ros, scoring = 'roc_auc', cv = folds)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9884834152324786"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean of all the scores of cross validation\n",
    "mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99028752, 0.99038476, 0.99085235, 0.990366  , 0.9902643 ])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression using cross validation and roc-auc as scoring matics\n",
    "lr = LogisticRegression()\n",
    "scores = cross_val_score(lr, X_train_smote, y_train_smote, scoring = 'roc_auc', cv = folds)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9904309840204744"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean of all the scores of cross validation\n",
    "mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here in logistic Regression we see that the SMOTE balacing method gives the best result.\n",
    "- We will use the SMOTE balaced dataset for doing hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression algorithm best parameter are : LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# step-1: create a cross-validation scheme\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{\"penalty\": ['l1', 'l2'],'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}]\n",
    "lm = LogisticRegression()\n",
    "model_cv_lr = GridSearchCV(lm, hyper_params, cv = folds, scoring = 'roc_auc', return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv_lr.fit(X_train_smote, y_train_smote)  \n",
    "# get the best parameter\n",
    "best_param = model_cv_lr.best_estimator_\n",
    "print('{} algorithm best parameter are : {}'.format('Logistic Regression',best_param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- here we could see that for c =1 and penalty = l2, we get the best result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final model of logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression using cross validation and roc-auc as scoring matics\n",
    "lr = LogisticRegression(C = 1, penalty = 'l2')\n",
    "lr.fit(X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9490428097678625"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roc-auc score\n",
    "y_train_pred = lr.predict(X_train_smote)\n",
    "roc_auc_score(y_train_smote,y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest with Random OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99992464, 0.99982417, 0.99992464, 0.99994976, 0.99989952])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "scores = cross_val_score(rf, X_train_ros, y_train_ros, scoring = 'precision', cv = folds)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999045431886946"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean of all the scores of cross validation\n",
    "mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999723, 0.99998626, 0.99999829, 0.99999869, 0.99999995])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "scores = cross_val_score(rf, X_train_smote, y_train_smote, scoring = 'roc_auc', cv = folds)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999960831463782"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean of all the scores of cross validation\n",
    "mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here in Random Forest Random OverSampling is giving better result so we will use this to tune the hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justification for Individual hyperparameter tuning - We tried tuning all paramters in one go but the execution time was quite high, even tried using Google's Colab and Online GPU supporting frameworks like Nimblebox, But was unable to complete tuning even after running algorith for more than 24 hours.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest algorithm best parameter are : RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter :Criterion\n",
    "# step-1: create a cross-validation scheme\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{\"criterion\": [\"gini\", \"entropy\"]}]\n",
    "lm = RandomForestClassifier()\n",
    "model_cv_rf = RandomizedSearchCV(lm, hyper_params, cv = folds, scoring = 'roc_auc', return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv_rf.fit(X_train_smote, y_train_smote)  \n",
    "# get the best parameter\n",
    "best_param = model_cv_rf.best_estimator_\n",
    "print('{} algorithm best parameter are : {}'.format('Random Forest',best_param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- criterion : gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest algorithm best parameter are : RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=6, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparamter : max_depth\n",
    "# step-1: create a cross-validation scheme\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{\"max_depth\": list(range(2,7,1))}]\n",
    "lm = RandomForestClassifier(criterion = 'gini')\n",
    "model_cv_rf = RandomizedSearchCV(lm, hyper_params, cv = folds, scoring = 'roc_auc', return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv_rf.fit(X_train_smote, y_train_smote)  \n",
    "# get the best parameter\n",
    "best_param = model_cv_rf.best_estimator_\n",
    "print('{} algorithm best parameter are : {}'.format('Random Forest',best_param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_depth = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest algorithm best parameter are : RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=6, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=8, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter : min_sample_leaf\n",
    "# step-1: create a cross-validation scheme\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{\"min_samples_leaf\": list(range(5,10,1))}]\n",
    "lm = RandomForestClassifier(criterion = 'gini',max_depth = 6)\n",
    "model_cv_rf = RandomizedSearchCV(lm, hyper_params, cv = folds, scoring = 'roc_auc', return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv_rf.fit(X_train_smote, y_train_smote)  \n",
    "# get the best parameter\n",
    "best_param = model_cv_rf.best_estimator_\n",
    "print('{} algorithm best parameter are : {}'.format('Random Forest',best_param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- min_sample_leaf = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest algorithm best parameter are : RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=6, max_features=18,\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=8, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# step-1: create a cross-validation scheme\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{'max_features': [4, 10, 18, 24]}]\n",
    "lm = RandomForestClassifier(criterion = 'gini',max_depth = 6,min_samples_leaf = 8)\n",
    "model_cv_rf = RandomizedSearchCV(lm, hyper_params, cv = folds, scoring = 'roc_auc', return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv_rf.fit(X_train_smote, y_train_smote)  \n",
    "# get the best parameter\n",
    "best_param = model_cv_rf.best_estimator_\n",
    "print('{} algorithm best parameter are : {}'.format('Random Forest',best_param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_features = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model for the Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=6, max_features=18,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=8, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv_rf = RandomForestClassifier(criterion = 'gini',max_depth = 6,min_samples_leaf = 8,max_features=18)\n",
    "model_cv_rf.fit(X_train_smote,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9785574314139283"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = model_cv_rf.predict(X_train_smote)\n",
    "roc_auc_score(y_train_smote,y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree with Random OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99968596, 0.99978645, 0.99981158, 0.99973621, 0.99977389])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "scores = cross_val_score(dt, X_train_ros, y_train_ros, scoring = 'roc_auc', cv = folds)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997588182092252"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean of all the scores of cross validation\n",
    "mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99801527, 0.99845493, 0.99839212, 0.9986936 , 0.99830419])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "scores = cross_val_score(dt, X_train_smote, y_train_smote, scoring = 'roc_auc', cv = folds)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9983720229122701"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean of all the scores of cross validation\n",
    "mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here in Decision Tree Random OverSampling gives the better result, so we will use this to tune the hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tunning for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree algorithm best parameter are : DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter : Criterion\n",
    "# step-1: create a cross-validation scheme\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{\"criterion\": [\"gini\", \"entropy\"]}]\n",
    "lm = DecisionTreeClassifier()\n",
    "model_cv_dt = GridSearchCV(lm, hyper_params, cv = folds, scoring = 'roc_auc', return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv_dt.fit(X_train_ros, y_train_ros)  \n",
    "# get the best parameter\n",
    "best_param = model_cv_dt.best_estimator_\n",
    "print('{} algorithm best parameter are : {}'.format('Decision Tree',best_param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Criterion : entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree algorithm best parameter are : DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
      "                       max_depth=9, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter : Max depth\n",
    "# step-1: create a cross-validation scheme\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{\"max_depth\": list(range(2,10,1))}]\n",
    "lm = DecisionTreeClassifier(criterion = 'entropy')\n",
    "model_cv_dt = GridSearchCV(lm, hyper_params, cv = folds, scoring = 'roc_auc', return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv_dt.fit(X_train_ros, y_train_ros)  \n",
    "# get the best parameter\n",
    "best_param = model_cv_dt.best_estimator_\n",
    "print('{} algorithm best parameter are : {}'.format('Decision Tree',best_param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_depth: 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree algorithm best parameter are : DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
      "                       max_depth=9, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter : min_sample_leaf\n",
    "# step-1: create a cross-validation scheme\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{\"min_samples_leaf\": list(range(1,10,2))}]\n",
    "lm = DecisionTreeClassifier(criterion = 'entropy',max_depth = 9)\n",
    "model_cv_dt = GridSearchCV(lm, hyper_params, cv = folds, scoring = 'roc_auc', return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv_dt.fit(X_train_ros, y_train_ros)  \n",
    "# get the best parameter\n",
    "best_param = model_cv_dt.best_estimator_\n",
    "print('{} algorithm best parameter are : {}'.format('Decision Tree',best_param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- min_sample_leaf:3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree algorithm best parameter are : DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
      "                       max_depth=9, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=16,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter : min_samples_split\n",
    "# step-1: create a cross-validation scheme\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{'min_samples_split': range(2, 20, 2)}]\n",
    "lm = DecisionTreeClassifier(criterion = 'entropy',max_depth = 9,min_samples_leaf = 3)\n",
    "model_cv_dt = GridSearchCV(lm, hyper_params, cv = folds, scoring = 'roc_auc', return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv_dt.fit(X_train_ros, y_train_ros)  \n",
    "# get the best parameter\n",
    "best_param = model_cv_dt.best_estimator_\n",
    "print('{} algorithm best parameter are : {}'.format('Decision Tree',best_param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- min_sample_split: 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=9, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=3, min_samples_split=16,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv_dt = DecisionTreeClassifier(criterion = 'entropy',max_depth = 9,min_samples_leaf = 3,min_samples_split=16)     \n",
    "model_cv_dt.fit(X_train_ros, y_train_ros)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9959803034870867"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = model_cv_dt.predict(X_train_ros)\n",
    "roc_auc_score(y_train_ros,y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost with Random OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.99998993, 0.99999993, 0.99999582, 1.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "scores = cross_val_score(xgb, X_train_ros, y_train_ros, scoring = 'roc_auc', cv = folds)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999971363802822"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean of all the scores of cross validation\n",
    "mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999632, 0.99999115, 0.99999252, 0.99999123, 0.99999662])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "scores = cross_val_score(xgb, X_train_smote, y_train_smote, scoring = 'roc_auc', cv = folds)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999935678695571"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean of all the scores of cross validation\n",
    "mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here in XGBoost Random Oversampling gives better result, so we will use this to train the hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost algorithm best parameter are : XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
      "              validate_parameters=False, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "# step-1: create a cross-validation scheme\n",
    "# hyperparameters- Max_depth\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{'max_depth':range(3,10,2)}]\n",
    "lm = XGBClassifier()\n",
    "model_cv_xgb = GridSearchCV(lm, hyper_params, cv = folds, scoring = 'roc_auc', return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv_xgb.fit(X_train_ros, y_train_ros)  \n",
    "# get the best parameter\n",
    "best_param = model_cv_xgb.best_estimator_\n",
    "print('{} algorithm best parameter are : {}'.format('XGBoost',best_param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost algorithm best parameter are : XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
      "              validate_parameters=False, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "# step-1: create a cross-validation scheme\n",
    "# hyperparameters- min_child_weight\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{'min_child_weight':range(1,6,2)}]\n",
    "lm = XGBClassifier(max_depth=5)\n",
    "model_cv_xgb = GridSearchCV(lm, hyper_params, cv = folds, scoring = 'roc_auc', return_train_score=True)      \n",
    "\n",
    "# fit the model\n",
    "model_cv_xgb.fit(X_train_ros, y_train_ros)  \n",
    "# get the best parameter\n",
    "best_param = model_cv_xgb.best_estimator_\n",
    "print('{} algorithm best parameter are : {}'.format('XGBoost',best_param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- min_child_weight : 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final model of XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cv_xgb = XGBClassifier(max_depth=5,min_child_weight=1)    \n",
    "model_cv_xgb.fit(X_train_ros, y_train_ros)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997412320369813"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = model_cv_xgb.predict(X_train_ros)\n",
    "roc_auc_score(y_train_ros,y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost model is being selected as the final model as it has the best ROC_AUC. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the final model for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = model_cv_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc : 0.9253239551762326\n",
      "Recall : 0.8513513513513513\n",
      "Precision : 0.6774193548387096\n",
      "F1-Score : 0.7544910179640719\n"
     ]
    }
   ],
   "source": [
    "# roc_auc, recall_score, precision_score, f1_score\n",
    "print(\"roc_auc :\", roc_auc_score(y_test, predictions))\n",
    "print(\"Recall :\", recall_score(y_test, predictions))\n",
    "print(\"Precision :\", precision_score(y_test, predictions))\n",
    "print(\"F1-Score :\", f1_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85235,    60],\n",
       "       [   22,   126]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrics\n",
    "confusion = metrics.confusion_matrix(y_test, predictions )\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.9990402958697612\n",
      "Sensitivity:  0.8513513513513513\n",
      "Specificity:  0.9992965590011138\n",
      "false postive rate:  0.0007034409988862184\n",
      "positive predictive value:  0.6774193548387096\n",
      "Negative predictive value:  0.9997419566721795\n"
     ]
    }
   ],
   "source": [
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives\n",
    "\n",
    "\n",
    "print('Accuracy Score: ',accuracy_score(y_test,predictions))\n",
    "# Let's see the sensitivity of our logistic regression model\n",
    "print('Sensitivity: ', TP / float(TP+FN))\n",
    "\n",
    "# Let us calculate specificity\n",
    "print('Specificity: ',TN / float(TN+FP))\n",
    "\n",
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "print('false postive rate: ',FP/ float(TN+FP))\n",
    "\n",
    "# positive predictive value \n",
    "print('positive predictive value: ', TP / float(TP+FP))\n",
    "\n",
    "# Negative predictive value\n",
    "print('Negative predictive value: ',TN / float(TN+ FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost-Benefit Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total fraud predictions that the model has made (TP + FP)\n",
    "total_fraud_prediction = TP + FP\n",
    "total_fraud_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>262922</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123418</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206135</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273483</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245758</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109541</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41813</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16722</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36147</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198375</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85443 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        y_pred\n",
       "262922       0\n",
       "123418       0\n",
       "206135       0\n",
       "273483       0\n",
       "245758       0\n",
       "...        ...\n",
       "109541       0\n",
       "41813        0\n",
       "16722        0\n",
       "36147        0\n",
       "198375       0\n",
       "\n",
       "[85443 rows x 1 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting prediction into a Data Frame with index of test dataset\n",
    "y_predict = pd.DataFrame(data = predictions, columns = ['y_pred'], index = X_test.index.copy())\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y_pred    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values\n",
    "y_predict.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024 -0.054952  ...  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  y_pred  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0     NaN  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0     NaN  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0     0.0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0     NaN  \n",
       "4  0.502292  0.219422  0.215153   69.99      0     NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging the original df and y_predict\n",
    "result = pd.merge(df,y_predict[['y_pred']],how ='left', left_index = True,right_index =True)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>-0.366846</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.449044</td>\n",
       "      <td>-1.176339</td>\n",
       "      <td>0.913860</td>\n",
       "      <td>-1.375667</td>\n",
       "      <td>-1.971383</td>\n",
       "      <td>-0.629152</td>\n",
       "      <td>-1.423236</td>\n",
       "      <td>0.048456</td>\n",
       "      <td>-1.720408</td>\n",
       "      <td>1.626659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313894</td>\n",
       "      <td>0.027740</td>\n",
       "      <td>0.500512</td>\n",
       "      <td>0.251367</td>\n",
       "      <td>-0.129478</td>\n",
       "      <td>0.042850</td>\n",
       "      <td>0.016253</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.436905</td>\n",
       "      <td>0.918966</td>\n",
       "      <td>0.924591</td>\n",
       "      <td>-0.727219</td>\n",
       "      <td>0.915679</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>0.707642</td>\n",
       "      <td>0.087962</td>\n",
       "      <td>-0.665271</td>\n",
       "      <td>-0.737980</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.672638</td>\n",
       "      <td>-0.156858</td>\n",
       "      <td>-0.888386</td>\n",
       "      <td>-0.342413</td>\n",
       "      <td>-0.049027</td>\n",
       "      <td>0.079692</td>\n",
       "      <td>0.131024</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.694885</td>\n",
       "      <td>-1.361819</td>\n",
       "      <td>1.029221</td>\n",
       "      <td>0.834159</td>\n",
       "      <td>-1.191209</td>\n",
       "      <td>1.309109</td>\n",
       "      <td>-0.878586</td>\n",
       "      <td>0.445290</td>\n",
       "      <td>-0.446196</td>\n",
       "      <td>0.568521</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.571955</td>\n",
       "      <td>-0.050881</td>\n",
       "      <td>-0.304215</td>\n",
       "      <td>0.072001</td>\n",
       "      <td>-0.422234</td>\n",
       "      <td>0.086553</td>\n",
       "      <td>0.063499</td>\n",
       "      <td>231.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          V1        V2        V3        V4        V5        V6        V7  \\\n",
       "2  -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "9  -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "10  1.449044 -1.176339  0.913860 -1.375667 -1.971383 -0.629152 -1.423236   \n",
       "17 -0.436905  0.918966  0.924591 -0.727219  0.915679 -0.127867  0.707642   \n",
       "20  0.694885 -1.361819  1.029221  0.834159 -1.191209  1.309109 -0.878586   \n",
       "\n",
       "          V8        V9       V10  ...       V22       V23       V24       V25  \\\n",
       "2   0.247676 -1.514654  0.207643  ...  0.771679  0.909412 -0.689281 -0.327642   \n",
       "9   0.069539 -0.736727 -0.366846  ... -0.633753 -0.120794 -0.385050 -0.069733   \n",
       "10  0.048456 -1.720408  1.626659  ...  0.313894  0.027740  0.500512  0.251367   \n",
       "17  0.087962 -0.665271 -0.737980  ... -0.672638 -0.156858 -0.888386 -0.342413   \n",
       "20  0.445290 -0.446196  0.568521  ... -0.571955 -0.050881 -0.304215  0.072001   \n",
       "\n",
       "         V26       V27       V28  Amount  Class  y_pred  \n",
       "2  -0.139097 -0.055353 -0.059752  378.66      0     0.0  \n",
       "9   0.094199  0.246219  0.083076    3.68      0     0.0  \n",
       "10 -0.129478  0.042850  0.016253    7.80      0     0.0  \n",
       "17 -0.049027  0.079692  0.131024    0.89      0     0.0  \n",
       "20 -0.422234  0.086553  0.063499  231.71      0     0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping all the rows having null values so that only test cases remain\n",
    "result = result.dropna()\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again checking for the null values\n",
    "result['y_pred'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>-4.801637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6529</th>\n",
       "      <td>-1.585505</td>\n",
       "      <td>3.261585</td>\n",
       "      <td>-4.137422</td>\n",
       "      <td>2.357096</td>\n",
       "      <td>-1.405043</td>\n",
       "      <td>-1.879437</td>\n",
       "      <td>-3.513687</td>\n",
       "      <td>1.515607</td>\n",
       "      <td>-1.207166</td>\n",
       "      <td>-6.234561</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.546869</td>\n",
       "      <td>-0.076584</td>\n",
       "      <td>-0.425550</td>\n",
       "      <td>0.123644</td>\n",
       "      <td>0.321985</td>\n",
       "      <td>0.264028</td>\n",
       "      <td>0.132817</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6719</th>\n",
       "      <td>-0.251471</td>\n",
       "      <td>4.313523</td>\n",
       "      <td>-6.891438</td>\n",
       "      <td>6.796797</td>\n",
       "      <td>0.616297</td>\n",
       "      <td>-2.966327</td>\n",
       "      <td>-2.436653</td>\n",
       "      <td>0.489328</td>\n",
       "      <td>-3.371639</td>\n",
       "      <td>-6.810813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.546126</td>\n",
       "      <td>-0.605240</td>\n",
       "      <td>-0.263743</td>\n",
       "      <td>1.539916</td>\n",
       "      <td>0.523574</td>\n",
       "      <td>0.891025</td>\n",
       "      <td>0.572741</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6820</th>\n",
       "      <td>-2.169929</td>\n",
       "      <td>3.639654</td>\n",
       "      <td>-4.508498</td>\n",
       "      <td>2.730668</td>\n",
       "      <td>-2.122693</td>\n",
       "      <td>-2.341017</td>\n",
       "      <td>-4.235253</td>\n",
       "      <td>1.703538</td>\n",
       "      <td>-1.305279</td>\n",
       "      <td>-6.716720</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.503529</td>\n",
       "      <td>-0.000523</td>\n",
       "      <td>0.071696</td>\n",
       "      <td>0.092007</td>\n",
       "      <td>0.308498</td>\n",
       "      <td>0.552591</td>\n",
       "      <td>0.298954</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6903</th>\n",
       "      <td>-2.535852</td>\n",
       "      <td>5.793644</td>\n",
       "      <td>-7.618463</td>\n",
       "      <td>6.395830</td>\n",
       "      <td>-0.065210</td>\n",
       "      <td>-3.136372</td>\n",
       "      <td>-3.104557</td>\n",
       "      <td>1.823233</td>\n",
       "      <td>-3.878658</td>\n",
       "      <td>-7.297803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.448060</td>\n",
       "      <td>-0.402407</td>\n",
       "      <td>-0.288835</td>\n",
       "      <td>1.011752</td>\n",
       "      <td>0.425965</td>\n",
       "      <td>0.413140</td>\n",
       "      <td>0.308205</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258403</th>\n",
       "      <td>-5.976119</td>\n",
       "      <td>-7.196980</td>\n",
       "      <td>-5.388316</td>\n",
       "      <td>5.104799</td>\n",
       "      <td>4.676533</td>\n",
       "      <td>-5.566870</td>\n",
       "      <td>-4.291180</td>\n",
       "      <td>0.876531</td>\n",
       "      <td>-1.075478</td>\n",
       "      <td>-3.272569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136262</td>\n",
       "      <td>0.848177</td>\n",
       "      <td>-0.269916</td>\n",
       "      <td>-1.095060</td>\n",
       "      <td>-0.710905</td>\n",
       "      <td>0.565846</td>\n",
       "      <td>-1.034107</td>\n",
       "      <td>296.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261056</th>\n",
       "      <td>-0.408111</td>\n",
       "      <td>3.132944</td>\n",
       "      <td>-3.098030</td>\n",
       "      <td>5.803893</td>\n",
       "      <td>0.890609</td>\n",
       "      <td>-0.501474</td>\n",
       "      <td>-0.440054</td>\n",
       "      <td>0.591828</td>\n",
       "      <td>-3.267693</td>\n",
       "      <td>-2.223070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.538375</td>\n",
       "      <td>-0.217989</td>\n",
       "      <td>-1.042657</td>\n",
       "      <td>0.314389</td>\n",
       "      <td>0.543244</td>\n",
       "      <td>0.233851</td>\n",
       "      <td>0.119603</td>\n",
       "      <td>45.51</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261925</th>\n",
       "      <td>-2.783865</td>\n",
       "      <td>1.596824</td>\n",
       "      <td>-2.084844</td>\n",
       "      <td>2.512986</td>\n",
       "      <td>-1.446749</td>\n",
       "      <td>-0.828496</td>\n",
       "      <td>-0.732262</td>\n",
       "      <td>-0.203329</td>\n",
       "      <td>-0.347046</td>\n",
       "      <td>-2.162061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293268</td>\n",
       "      <td>0.199568</td>\n",
       "      <td>0.146868</td>\n",
       "      <td>0.163602</td>\n",
       "      <td>-0.624085</td>\n",
       "      <td>-1.333100</td>\n",
       "      <td>0.428634</td>\n",
       "      <td>156.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262826</th>\n",
       "      <td>-0.417340</td>\n",
       "      <td>4.700055</td>\n",
       "      <td>-7.521767</td>\n",
       "      <td>7.671884</td>\n",
       "      <td>0.260821</td>\n",
       "      <td>-2.646693</td>\n",
       "      <td>-2.854432</td>\n",
       "      <td>0.958783</td>\n",
       "      <td>-4.588536</td>\n",
       "      <td>-6.120715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.437708</td>\n",
       "      <td>-0.090358</td>\n",
       "      <td>-0.742802</td>\n",
       "      <td>-0.312361</td>\n",
       "      <td>0.502575</td>\n",
       "      <td>0.821390</td>\n",
       "      <td>0.372379</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280149</th>\n",
       "      <td>-0.676143</td>\n",
       "      <td>1.126366</td>\n",
       "      <td>-2.213700</td>\n",
       "      <td>0.468308</td>\n",
       "      <td>-1.120541</td>\n",
       "      <td>-0.003346</td>\n",
       "      <td>-2.234739</td>\n",
       "      <td>1.210158</td>\n",
       "      <td>-0.652250</td>\n",
       "      <td>-3.463891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834108</td>\n",
       "      <td>0.190944</td>\n",
       "      <td>0.032070</td>\n",
       "      <td>-0.739695</td>\n",
       "      <td>0.471111</td>\n",
       "      <td>0.385107</td>\n",
       "      <td>0.194361</td>\n",
       "      <td>77.89</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "6108   -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536 -3.496197   \n",
       "6529   -1.585505  3.261585 -4.137422  2.357096 -1.405043 -1.879437 -3.513687   \n",
       "6719   -0.251471  4.313523 -6.891438  6.796797  0.616297 -2.966327 -2.436653   \n",
       "6820   -2.169929  3.639654 -4.508498  2.730668 -2.122693 -2.341017 -4.235253   \n",
       "6903   -2.535852  5.793644 -7.618463  6.395830 -0.065210 -3.136372 -3.104557   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "258403 -5.976119 -7.196980 -5.388316  5.104799  4.676533 -5.566870 -4.291180   \n",
       "261056 -0.408111  3.132944 -3.098030  5.803893  0.890609 -0.501474 -0.440054   \n",
       "261925 -2.783865  1.596824 -2.084844  2.512986 -1.446749 -0.828496 -0.732262   \n",
       "262826 -0.417340  4.700055 -7.521767  7.671884  0.260821 -2.646693 -2.854432   \n",
       "280149 -0.676143  1.126366 -2.213700  0.468308 -1.120541 -0.003346 -2.234739   \n",
       "\n",
       "              V8        V9       V10  ...       V22       V23       V24  \\\n",
       "6108   -0.248778 -0.247768 -4.801637  ...  0.176968 -0.436207 -0.053502   \n",
       "6529    1.515607 -1.207166 -6.234561  ... -0.546869 -0.076584 -0.425550   \n",
       "6719    0.489328 -3.371639 -6.810813  ... -0.546126 -0.605240 -0.263743   \n",
       "6820    1.703538 -1.305279 -6.716720  ... -0.503529 -0.000523  0.071696   \n",
       "6903    1.823233 -3.878658 -7.297803  ... -0.448060 -0.402407 -0.288835   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "258403  0.876531 -1.075478 -3.272569  ... -0.136262  0.848177 -0.269916   \n",
       "261056  0.591828 -3.267693 -2.223070  ... -0.538375 -0.217989 -1.042657   \n",
       "261925 -0.203329 -0.347046 -2.162061  ...  0.293268  0.199568  0.146868   \n",
       "262826  0.958783 -4.588536 -6.120715  ... -0.437708 -0.090358 -0.742802   \n",
       "280149  1.210158 -0.652250 -3.463891  ...  0.834108  0.190944  0.032070   \n",
       "\n",
       "             V25       V26       V27       V28  Amount  Class  y_pred  \n",
       "6108    0.252405 -0.657488 -0.827136  0.849573   59.00      1     1.0  \n",
       "6529    0.123644  0.321985  0.264028  0.132817    1.00      1     1.0  \n",
       "6719    1.539916  0.523574  0.891025  0.572741    1.00      1     1.0  \n",
       "6820    0.092007  0.308498  0.552591  0.298954    1.00      1     1.0  \n",
       "6903    1.011752  0.425965  0.413140  0.308205    1.00      1     1.0  \n",
       "...          ...       ...       ...       ...     ...    ...     ...  \n",
       "258403 -1.095060 -0.710905  0.565846 -1.034107  296.00      1     1.0  \n",
       "261056  0.314389  0.543244  0.233851  0.119603   45.51      1     1.0  \n",
       "261925  0.163602 -0.624085 -1.333100  0.428634  156.00      1     1.0  \n",
       "262826 -0.312361  0.502575  0.821390  0.372379    0.77      1     1.0  \n",
       "280149 -0.739695  0.471111  0.385107  0.194361   77.89      1     1.0  \n",
       "\n",
       "[126 rows x 31 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data frame of all the people with both y_test and prediction being positive\n",
    "correct_df = result[(result['Class'] == 1) &(result['y_pred'] == 1)]\n",
    "correct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29687</th>\n",
       "      <td>-2.019001</td>\n",
       "      <td>1.491270</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.817253</td>\n",
       "      <td>0.973252</td>\n",
       "      <td>-0.639268</td>\n",
       "      <td>-0.974073</td>\n",
       "      <td>-3.146929</td>\n",
       "      <td>-0.003159</td>\n",
       "      <td>-0.121653</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.185443</td>\n",
       "      <td>-0.142812</td>\n",
       "      <td>-0.086103</td>\n",
       "      <td>-0.329113</td>\n",
       "      <td>0.523601</td>\n",
       "      <td>0.626283</td>\n",
       "      <td>0.152440</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52521</th>\n",
       "      <td>1.001992</td>\n",
       "      <td>0.047938</td>\n",
       "      <td>-0.349002</td>\n",
       "      <td>1.493958</td>\n",
       "      <td>0.186939</td>\n",
       "      <td>0.190966</td>\n",
       "      <td>-0.001112</td>\n",
       "      <td>0.147140</td>\n",
       "      <td>0.580415</td>\n",
       "      <td>-0.792938</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.014315</td>\n",
       "      <td>-0.128427</td>\n",
       "      <td>-0.946242</td>\n",
       "      <td>0.456090</td>\n",
       "      <td>-0.453206</td>\n",
       "      <td>0.046627</td>\n",
       "      <td>0.064698</td>\n",
       "      <td>105.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55401</th>\n",
       "      <td>-0.481531</td>\n",
       "      <td>1.059542</td>\n",
       "      <td>0.647117</td>\n",
       "      <td>0.905586</td>\n",
       "      <td>0.819368</td>\n",
       "      <td>-0.091184</td>\n",
       "      <td>0.504135</td>\n",
       "      <td>0.161064</td>\n",
       "      <td>-0.765054</td>\n",
       "      <td>-0.550545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192491</td>\n",
       "      <td>-0.174659</td>\n",
       "      <td>-0.438908</td>\n",
       "      <td>0.239259</td>\n",
       "      <td>-0.217823</td>\n",
       "      <td>-0.072852</td>\n",
       "      <td>0.010463</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58422</th>\n",
       "      <td>-2.790771</td>\n",
       "      <td>-1.464269</td>\n",
       "      <td>1.031165</td>\n",
       "      <td>1.921356</td>\n",
       "      <td>-0.090014</td>\n",
       "      <td>-0.483871</td>\n",
       "      <td>0.780731</td>\n",
       "      <td>-0.348776</td>\n",
       "      <td>0.609133</td>\n",
       "      <td>0.225934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440020</td>\n",
       "      <td>0.777659</td>\n",
       "      <td>0.418552</td>\n",
       "      <td>0.244563</td>\n",
       "      <td>-0.159361</td>\n",
       "      <td>0.060540</td>\n",
       "      <td>0.356958</td>\n",
       "      <td>208.58</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68067</th>\n",
       "      <td>-1.101847</td>\n",
       "      <td>-1.632441</td>\n",
       "      <td>0.901067</td>\n",
       "      <td>0.847753</td>\n",
       "      <td>-1.249091</td>\n",
       "      <td>0.654937</td>\n",
       "      <td>1.448868</td>\n",
       "      <td>0.023308</td>\n",
       "      <td>-0.136742</td>\n",
       "      <td>-0.150129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835795</td>\n",
       "      <td>1.179955</td>\n",
       "      <td>-0.029091</td>\n",
       "      <td>-0.300896</td>\n",
       "      <td>0.699175</td>\n",
       "      <td>-0.336072</td>\n",
       "      <td>-0.177587</td>\n",
       "      <td>519.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68633</th>\n",
       "      <td>1.296231</td>\n",
       "      <td>0.417447</td>\n",
       "      <td>0.193963</td>\n",
       "      <td>0.901644</td>\n",
       "      <td>0.130531</td>\n",
       "      <td>-0.371634</td>\n",
       "      <td>0.158126</td>\n",
       "      <td>-0.202669</td>\n",
       "      <td>-0.079512</td>\n",
       "      <td>-0.045088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.220002</td>\n",
       "      <td>-0.121022</td>\n",
       "      <td>-0.440454</td>\n",
       "      <td>0.671540</td>\n",
       "      <td>-0.413518</td>\n",
       "      <td>0.032838</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72757</th>\n",
       "      <td>-2.986466</td>\n",
       "      <td>-0.000891</td>\n",
       "      <td>0.605887</td>\n",
       "      <td>0.338338</td>\n",
       "      <td>0.685448</td>\n",
       "      <td>-1.581954</td>\n",
       "      <td>0.504206</td>\n",
       "      <td>-0.233403</td>\n",
       "      <td>0.636768</td>\n",
       "      <td>1.010291</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.509849</td>\n",
       "      <td>1.313918</td>\n",
       "      <td>0.355065</td>\n",
       "      <td>0.448552</td>\n",
       "      <td>0.193490</td>\n",
       "      <td>1.214588</td>\n",
       "      <td>-0.013923</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96341</th>\n",
       "      <td>1.227614</td>\n",
       "      <td>-0.668974</td>\n",
       "      <td>-0.271785</td>\n",
       "      <td>-0.589440</td>\n",
       "      <td>-0.604795</td>\n",
       "      <td>-0.350285</td>\n",
       "      <td>-0.486365</td>\n",
       "      <td>-0.010809</td>\n",
       "      <td>-0.794944</td>\n",
       "      <td>0.264545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.295255</td>\n",
       "      <td>-0.180459</td>\n",
       "      <td>-0.436539</td>\n",
       "      <td>0.494649</td>\n",
       "      <td>-0.283738</td>\n",
       "      <td>-0.001128</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>98.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101509</th>\n",
       "      <td>-1.739334</td>\n",
       "      <td>-1.304655</td>\n",
       "      <td>0.314103</td>\n",
       "      <td>0.053740</td>\n",
       "      <td>-0.058696</td>\n",
       "      <td>0.071260</td>\n",
       "      <td>0.694862</td>\n",
       "      <td>-0.313270</td>\n",
       "      <td>-0.649377</td>\n",
       "      <td>0.517568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.632078</td>\n",
       "      <td>-0.421176</td>\n",
       "      <td>-0.400774</td>\n",
       "      <td>-0.001640</td>\n",
       "      <td>-0.495162</td>\n",
       "      <td>0.031633</td>\n",
       "      <td>0.066280</td>\n",
       "      <td>320.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112840</th>\n",
       "      <td>-1.111495</td>\n",
       "      <td>-0.257575</td>\n",
       "      <td>2.250210</td>\n",
       "      <td>1.152671</td>\n",
       "      <td>0.432904</td>\n",
       "      <td>1.254126</td>\n",
       "      <td>-0.584163</td>\n",
       "      <td>-0.609682</td>\n",
       "      <td>1.014602</td>\n",
       "      <td>0.334533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927825</td>\n",
       "      <td>-0.343058</td>\n",
       "      <td>-0.256268</td>\n",
       "      <td>-0.600742</td>\n",
       "      <td>-0.180331</td>\n",
       "      <td>0.026762</td>\n",
       "      <td>-0.358335</td>\n",
       "      <td>45.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118308</th>\n",
       "      <td>-0.430330</td>\n",
       "      <td>0.985633</td>\n",
       "      <td>0.645789</td>\n",
       "      <td>0.317131</td>\n",
       "      <td>0.616332</td>\n",
       "      <td>-1.347462</td>\n",
       "      <td>1.078234</td>\n",
       "      <td>-0.161518</td>\n",
       "      <td>-0.492856</td>\n",
       "      <td>-1.039638</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207609</td>\n",
       "      <td>-0.164119</td>\n",
       "      <td>0.255280</td>\n",
       "      <td>0.454798</td>\n",
       "      <td>-0.505032</td>\n",
       "      <td>-0.039456</td>\n",
       "      <td>-0.006358</td>\n",
       "      <td>30.14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119714</th>\n",
       "      <td>-0.734303</td>\n",
       "      <td>0.435519</td>\n",
       "      <td>-0.530866</td>\n",
       "      <td>-0.471120</td>\n",
       "      <td>0.643214</td>\n",
       "      <td>0.713832</td>\n",
       "      <td>-1.234572</td>\n",
       "      <td>-2.551412</td>\n",
       "      <td>-2.057724</td>\n",
       "      <td>0.166831</td>\n",
       "      <td>...</td>\n",
       "      <td>1.150354</td>\n",
       "      <td>-0.152555</td>\n",
       "      <td>-1.386745</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>0.219146</td>\n",
       "      <td>-0.058257</td>\n",
       "      <td>0.158048</td>\n",
       "      <td>29.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142557</th>\n",
       "      <td>-1.430864</td>\n",
       "      <td>-0.802529</td>\n",
       "      <td>1.123320</td>\n",
       "      <td>0.389760</td>\n",
       "      <td>-0.281214</td>\n",
       "      <td>-0.055123</td>\n",
       "      <td>1.326232</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>-0.546890</td>\n",
       "      <td>-0.713474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014002</td>\n",
       "      <td>0.844946</td>\n",
       "      <td>0.114963</td>\n",
       "      <td>0.156365</td>\n",
       "      <td>-0.619437</td>\n",
       "      <td>-0.120351</td>\n",
       "      <td>0.035594</td>\n",
       "      <td>354.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144754</th>\n",
       "      <td>-0.670238</td>\n",
       "      <td>0.945206</td>\n",
       "      <td>0.610051</td>\n",
       "      <td>2.640065</td>\n",
       "      <td>-2.707775</td>\n",
       "      <td>1.952611</td>\n",
       "      <td>-1.624608</td>\n",
       "      <td>-5.229908</td>\n",
       "      <td>0.210202</td>\n",
       "      <td>-2.069904</td>\n",
       "      <td>...</td>\n",
       "      <td>1.436472</td>\n",
       "      <td>0.351542</td>\n",
       "      <td>0.648467</td>\n",
       "      <td>0.579681</td>\n",
       "      <td>0.075738</td>\n",
       "      <td>0.346717</td>\n",
       "      <td>0.282209</td>\n",
       "      <td>323.77</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157585</th>\n",
       "      <td>1.934946</td>\n",
       "      <td>0.650678</td>\n",
       "      <td>-0.286957</td>\n",
       "      <td>3.987828</td>\n",
       "      <td>0.316052</td>\n",
       "      <td>-0.099449</td>\n",
       "      <td>-0.021483</td>\n",
       "      <td>-0.172327</td>\n",
       "      <td>0.508730</td>\n",
       "      <td>1.072955</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190974</td>\n",
       "      <td>0.219976</td>\n",
       "      <td>-0.216597</td>\n",
       "      <td>-0.136692</td>\n",
       "      <td>-0.129954</td>\n",
       "      <td>-0.050077</td>\n",
       "      <td>-0.051082</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197586</th>\n",
       "      <td>-0.361428</td>\n",
       "      <td>1.133472</td>\n",
       "      <td>-2.971360</td>\n",
       "      <td>-0.283073</td>\n",
       "      <td>0.371452</td>\n",
       "      <td>-0.574680</td>\n",
       "      <td>4.031513</td>\n",
       "      <td>-0.934398</td>\n",
       "      <td>-0.768255</td>\n",
       "      <td>-2.248115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563861</td>\n",
       "      <td>-0.408436</td>\n",
       "      <td>-0.880079</td>\n",
       "      <td>1.408392</td>\n",
       "      <td>-0.137402</td>\n",
       "      <td>-0.001250</td>\n",
       "      <td>-0.182751</td>\n",
       "      <td>480.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214775</th>\n",
       "      <td>-0.395582</td>\n",
       "      <td>-0.751792</td>\n",
       "      <td>-1.984666</td>\n",
       "      <td>-0.203459</td>\n",
       "      <td>1.903967</td>\n",
       "      <td>-1.430289</td>\n",
       "      <td>-0.076548</td>\n",
       "      <td>-0.992260</td>\n",
       "      <td>0.756307</td>\n",
       "      <td>0.217630</td>\n",
       "      <td>...</td>\n",
       "      <td>2.151787</td>\n",
       "      <td>0.189225</td>\n",
       "      <td>0.772943</td>\n",
       "      <td>-0.872443</td>\n",
       "      <td>-0.200612</td>\n",
       "      <td>0.356856</td>\n",
       "      <td>0.032113</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222419</th>\n",
       "      <td>0.457845</td>\n",
       "      <td>1.373769</td>\n",
       "      <td>-0.488926</td>\n",
       "      <td>2.805351</td>\n",
       "      <td>1.777386</td>\n",
       "      <td>0.100492</td>\n",
       "      <td>1.295016</td>\n",
       "      <td>-0.135857</td>\n",
       "      <td>-1.695822</td>\n",
       "      <td>0.955004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371014</td>\n",
       "      <td>0.051105</td>\n",
       "      <td>0.401524</td>\n",
       "      <td>-0.724766</td>\n",
       "      <td>-0.202881</td>\n",
       "      <td>0.092124</td>\n",
       "      <td>0.094956</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239501</th>\n",
       "      <td>-6.682832</td>\n",
       "      <td>-2.714268</td>\n",
       "      <td>-5.774530</td>\n",
       "      <td>1.449792</td>\n",
       "      <td>-0.661836</td>\n",
       "      <td>-1.148650</td>\n",
       "      <td>0.849686</td>\n",
       "      <td>0.433427</td>\n",
       "      <td>-1.315646</td>\n",
       "      <td>-2.796332</td>\n",
       "      <td>...</td>\n",
       "      <td>1.187013</td>\n",
       "      <td>0.335821</td>\n",
       "      <td>0.215683</td>\n",
       "      <td>0.803110</td>\n",
       "      <td>0.044033</td>\n",
       "      <td>-0.054988</td>\n",
       "      <td>0.082337</td>\n",
       "      <td>237.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245556</th>\n",
       "      <td>1.322724</td>\n",
       "      <td>-0.843911</td>\n",
       "      <td>-2.096888</td>\n",
       "      <td>0.759759</td>\n",
       "      <td>-0.196377</td>\n",
       "      <td>-1.166353</td>\n",
       "      <td>0.482534</td>\n",
       "      <td>-0.349791</td>\n",
       "      <td>1.045007</td>\n",
       "      <td>-1.474974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121562</td>\n",
       "      <td>-0.208574</td>\n",
       "      <td>-0.254752</td>\n",
       "      <td>-0.098324</td>\n",
       "      <td>-0.613874</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.072386</td>\n",
       "      <td>357.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249239</th>\n",
       "      <td>-0.082983</td>\n",
       "      <td>-3.935919</td>\n",
       "      <td>-2.616709</td>\n",
       "      <td>0.163310</td>\n",
       "      <td>-1.400952</td>\n",
       "      <td>-0.809419</td>\n",
       "      <td>1.501580</td>\n",
       "      <td>-0.471000</td>\n",
       "      <td>1.519743</td>\n",
       "      <td>-1.134454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.182305</td>\n",
       "      <td>-0.921017</td>\n",
       "      <td>0.111635</td>\n",
       "      <td>-0.071622</td>\n",
       "      <td>-1.125881</td>\n",
       "      <td>-0.170947</td>\n",
       "      <td>0.126221</td>\n",
       "      <td>1096.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263080</th>\n",
       "      <td>2.132386</td>\n",
       "      <td>0.705608</td>\n",
       "      <td>-3.530759</td>\n",
       "      <td>0.514779</td>\n",
       "      <td>1.527175</td>\n",
       "      <td>-1.716268</td>\n",
       "      <td>1.132791</td>\n",
       "      <td>-0.574214</td>\n",
       "      <td>0.128904</td>\n",
       "      <td>-1.000805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703910</td>\n",
       "      <td>-0.245076</td>\n",
       "      <td>0.460049</td>\n",
       "      <td>0.920281</td>\n",
       "      <td>-0.216586</td>\n",
       "      <td>-0.026219</td>\n",
       "      <td>-0.025001</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "29687  -2.019001  1.491270  0.005222  0.817253  0.973252 -0.639268 -0.974073   \n",
       "52521   1.001992  0.047938 -0.349002  1.493958  0.186939  0.190966 -0.001112   \n",
       "55401  -0.481531  1.059542  0.647117  0.905586  0.819368 -0.091184  0.504135   \n",
       "58422  -2.790771 -1.464269  1.031165  1.921356 -0.090014 -0.483871  0.780731   \n",
       "68067  -1.101847 -1.632441  0.901067  0.847753 -1.249091  0.654937  1.448868   \n",
       "68633   1.296231  0.417447  0.193963  0.901644  0.130531 -0.371634  0.158126   \n",
       "72757  -2.986466 -0.000891  0.605887  0.338338  0.685448 -1.581954  0.504206   \n",
       "96341   1.227614 -0.668974 -0.271785 -0.589440 -0.604795 -0.350285 -0.486365   \n",
       "101509 -1.739334 -1.304655  0.314103  0.053740 -0.058696  0.071260  0.694862   \n",
       "112840 -1.111495 -0.257575  2.250210  1.152671  0.432904  1.254126 -0.584163   \n",
       "118308 -0.430330  0.985633  0.645789  0.317131  0.616332 -1.347462  1.078234   \n",
       "119714 -0.734303  0.435519 -0.530866 -0.471120  0.643214  0.713832 -1.234572   \n",
       "142557 -1.430864 -0.802529  1.123320  0.389760 -0.281214 -0.055123  1.326232   \n",
       "144754 -0.670238  0.945206  0.610051  2.640065 -2.707775  1.952611 -1.624608   \n",
       "157585  1.934946  0.650678 -0.286957  3.987828  0.316052 -0.099449 -0.021483   \n",
       "197586 -0.361428  1.133472 -2.971360 -0.283073  0.371452 -0.574680  4.031513   \n",
       "214775 -0.395582 -0.751792 -1.984666 -0.203459  1.903967 -1.430289 -0.076548   \n",
       "222419  0.457845  1.373769 -0.488926  2.805351  1.777386  0.100492  1.295016   \n",
       "239501 -6.682832 -2.714268 -5.774530  1.449792 -0.661836 -1.148650  0.849686   \n",
       "245556  1.322724 -0.843911 -2.096888  0.759759 -0.196377 -1.166353  0.482534   \n",
       "249239 -0.082983 -3.935919 -2.616709  0.163310 -1.400952 -0.809419  1.501580   \n",
       "263080  2.132386  0.705608 -3.530759  0.514779  1.527175 -1.716268  1.132791   \n",
       "\n",
       "              V8        V9       V10  ...       V22       V23       V24  \\\n",
       "29687  -3.146929 -0.003159 -0.121653  ... -1.185443 -0.142812 -0.086103   \n",
       "52521   0.147140  0.580415 -0.792938  ... -1.014315 -0.128427 -0.946242   \n",
       "55401   0.161064 -0.765054 -0.550545  ...  0.192491 -0.174659 -0.438908   \n",
       "58422  -0.348776  0.609133  0.225934  ...  0.440020  0.777659  0.418552   \n",
       "68067   0.023308 -0.136742 -0.150129  ...  0.835795  1.179955 -0.029091   \n",
       "68633  -0.202669 -0.079512 -0.045088  ... -0.220002 -0.121022 -0.440454   \n",
       "72757  -0.233403  0.636768  1.010291  ... -0.509849  1.313918  0.355065   \n",
       "96341  -0.010809 -0.794944  0.264545  ... -0.295255 -0.180459 -0.436539   \n",
       "101509 -0.313270 -0.649377  0.517568  ... -0.632078 -0.421176 -0.400774   \n",
       "112840 -0.609682  1.014602  0.334533  ...  0.927825 -0.343058 -0.256268   \n",
       "118308 -0.161518 -0.492856 -1.039638  ... -0.207609 -0.164119  0.255280   \n",
       "119714 -2.551412 -2.057724  0.166831  ...  1.150354 -0.152555 -1.386745   \n",
       "142557  0.195700 -0.546890 -0.713474  ...  0.014002  0.844946  0.114963   \n",
       "144754 -5.229908  0.210202 -2.069904  ...  1.436472  0.351542  0.648467   \n",
       "157585 -0.172327  0.508730  1.072955  ... -0.190974  0.219976 -0.216597   \n",
       "197586 -0.934398 -0.768255 -2.248115  ...  0.563861 -0.408436 -0.880079   \n",
       "214775 -0.992260  0.756307  0.217630  ...  2.151787  0.189225  0.772943   \n",
       "222419 -0.135857 -1.695822  0.955004  ...  0.371014  0.051105  0.401524   \n",
       "239501  0.433427 -1.315646 -2.796332  ...  1.187013  0.335821  0.215683   \n",
       "245556 -0.349791  1.045007 -1.474974  ... -0.121562 -0.208574 -0.254752   \n",
       "249239 -0.471000  1.519743 -1.134454  ... -0.182305 -0.921017  0.111635   \n",
       "263080 -0.574214  0.128904 -1.000805  ...  0.703910 -0.245076  0.460049   \n",
       "\n",
       "             V25       V26       V27       V28   Amount  Class  y_pred  \n",
       "29687  -0.329113  0.523601  0.626283  0.152440     0.76      1     0.0  \n",
       "52521   0.456090 -0.453206  0.046627  0.064698   105.99      1     0.0  \n",
       "55401   0.239259 -0.217823 -0.072852  0.010463     1.00      1     0.0  \n",
       "58422   0.244563 -0.159361  0.060540  0.356958   208.58      1     0.0  \n",
       "68067  -0.300896  0.699175 -0.336072 -0.177587   519.90      1     0.0  \n",
       "68633   0.671540 -0.413518  0.032838  0.020600     1.18      1     0.0  \n",
       "72757   0.448552  0.193490  1.214588 -0.013923     1.79      1     0.0  \n",
       "96341   0.494649 -0.283738 -0.001128  0.035075    98.01      1     0.0  \n",
       "101509 -0.001640 -0.495162  0.031633  0.066280   320.00      1     0.0  \n",
       "112840 -0.600742 -0.180331  0.026762 -0.358335    45.03      1     0.0  \n",
       "118308  0.454798 -0.505032 -0.039456 -0.006358    30.14      1     0.0  \n",
       "119714  0.004716  0.219146 -0.058257  0.158048    29.95      1     0.0  \n",
       "142557  0.156365 -0.619437 -0.120351  0.035594   354.33      1     0.0  \n",
       "144754  0.579681  0.075738  0.346717  0.282209   323.77      1     0.0  \n",
       "157585 -0.136692 -0.129954 -0.050077 -0.051082     1.00      1     0.0  \n",
       "197586  1.408392 -0.137402 -0.001250 -0.182751   480.72      1     0.0  \n",
       "214775 -0.872443 -0.200612  0.356856  0.032113     0.69      1     0.0  \n",
       "222419 -0.724766 -0.202881  0.092124  0.094956     0.00      1     0.0  \n",
       "239501  0.803110  0.044033 -0.054988  0.082337   237.26      1     0.0  \n",
       "245556 -0.098324 -0.613874  0.002654  0.072386   357.95      1     0.0  \n",
       "249239 -0.071622 -1.125881 -0.170947  0.126221  1096.99      1     0.0  \n",
       "263080  0.920281 -0.216586 -0.026219 -0.025001     1.00      1     0.0  \n",
       "\n",
       "[22 rows x 31 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data frame of all the people with y_test being positive and prediction being negative\n",
    "losses_df = result[(result['Class'] == 1) &(result['y_pred'] == 0)]\n",
    "losses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13237.27"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total amount where both y_test and y_pred being positive\n",
    "cost_correct = correct_df['Amount'].sum()\n",
    "cost_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4216.04"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total amount where y_test positive but y_pred being negative\n",
    "cost_wrong = losses_df['Amount'].sum()\n",
    "cost_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1667896.02"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# savings will be the total amount of correct predictions made:\n",
    "# TP x Cost of each transaction which is correctly predicted.\n",
    "savings = TP * cost_correct\n",
    "savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92752.88"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The loss will be the total amount of incorrect predictions made:\n",
    "# FN x Cost of each transaction which is incorrectly predicted.\n",
    "loss = FN * cost_wrong\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1860"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cost of calling customer to confirm\n",
    "cost_to_call = 10 * (TP + FP)\n",
    "cost_to_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1573283.1400000001"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So the total savings = \n",
    "# savings - (cost_to_call + loss)\n",
    "# (TP x cost of each transaction -[(TP+FP) x 10 + FN x Cost of all transactions])\n",
    "total_savings = savings - (cost_to_call + loss)\n",
    "total_savings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Therefore the total saving is equal to = 1573283"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
